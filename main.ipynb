{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c65ea7a",
   "metadata": {},
   "source": [
    "\n",
    "# Word2Vec: Vanilla vs RSR (Human Behavioral Similarity)\n",
    "\n",
    "## Experiment Pipeline\n",
    "\n",
    "**Goal**: Compare two Word2Vec models on semantic similarity:\n",
    "1. **Vanilla**: Trained ONLY on Wikipedia corpus\n",
    "2. **RSR**: Trained on Wikipedia + Human similarity judgments (4.7M triplets)\n",
    "\n",
    "### Pipeline Steps:\n",
    "1. Load Wikipedia corpus\n",
    "2. Load human behavioral similarity matrix (THINGS dataset)\n",
    "3. Load THINGS concepts\n",
    "4. Train Word2Vec **VANILLA** (Wikipedia only)\n",
    "5. Train Word2Vec **RSR** (Wikipedia + human similarity)\n",
    "6. Evaluate both on **SimLex-999** benchmark (human similarity ratings)\n",
    "\n",
    "### RSR Approach: Three-Component Loss (Interpretation 2)\n",
    "\n",
    "The RSR model uses a **three-component loss** to balance general vocabulary learning with THINGS-focused training:\n",
    "\n",
    "**Loss Function:**\n",
    "```\n",
    "L_total = W2V_WEIGHT × L_w2v + THINGS_W2V_WEIGHT × L_things + RSR_WEIGHT × L_rsr\n",
    "```\n",
    "\n",
    "**Components:**\n",
    "1. **L_w2v** (0.7): General skip-gram on Wikipedia corpus\n",
    "   - Learns relationships between ALL words in the vocabulary\n",
    "   - Ensures broad language understanding\n",
    "\n",
    "2. **L_things** (0.2): THINGS-focused skip-gram\n",
    "   - Samples batches where TARGET words are THINGS concepts\n",
    "   - Ensures THINGS concepts see extra training signal in corpus context\n",
    "   - Helps them develop rich representations before RSR alignment\n",
    "\n",
    "3. **L_rsr** (0.1): Human similarity alignment\n",
    "   - Soft Spearman correlation with human behavioral similarity\n",
    "   - `L_rsr = 1 - soft_spearman(model_sim, human_sim)`\n",
    "   - Uses random sampling of concept pairs for efficiency\n",
    "\n",
    "**Why Three Components?**\n",
    "- The original two-component approach (L_w2v + L_rsr) had a stark separation: general vocabulary learning vs. THINGS similarity\n",
    "- This led to THINGS concepts being pulled toward each other by RSR but not learning rich context from the corpus\n",
    "- The three-component approach ensures THINGS concepts get extra corpus training while still learning human similarity patterns\n",
    "- This should help generalization: THINGS words learn both corpus context AND human similarity\n",
    "\n",
    "### Evaluation: SimLex-999 Benchmark\n",
    "\n",
    "We evaluate using **SimLex-999**, a gold-standard benchmark for semantic similarity (not relatedness). \n",
    "\n",
    "To test generalization, we split word pairs into three categories:\n",
    "- **Both in THINGS**: Both words were used during RSR training → tests direct learning\n",
    "- **One in THINGS**: Only one word was used → tests partial transfer\n",
    "- **Neither in THINGS**: Neither word was used → tests true generalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab82b3",
   "metadata": {},
   "source": [
    "## Step 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd41a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note: torchsort is the brain_chapter's choice, but it requires C++ compilation.\n",
    "# We use a pure PyTorch soft ranking implementation instead (see soft_rank below).\n",
    "\n",
    "# Configuration\n",
    "BASE_DATA_DIR = \"data\"\n",
    "THINGS_DIR = \"things_similarity\"\n",
    "\n",
    "# Corpus path (text file, one sentence per line)\n",
    "CORPUS_PATH = os.path.join(BASE_DATA_DIR, \"AllCombined.txt\")\n",
    "\n",
    "# THINGS paths\n",
    "THINGS_WORDS_PATH = os.path.join(THINGS_DIR, \"variables\", \"unique_id.txt\")\n",
    "BEHAVIORAL_SIM_PATH = os.path.join(THINGS_DIR, \"data\", \"spose_similarity.mat\")\n",
    "# Try category_mat_manual.mat which likely has the manual category labels\n",
    "CATEGORY_DATA_PATH = os.path.join(THINGS_DIR, \"data\", \"category_mat_manual.mat\")\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37402a11",
   "metadata": {},
   "source": [
    "## Step 2: Load Wikipedia Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b9dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 2: Loading Wikipedia Corpus\n",
      "======================================================================\n",
      "  Source: Wikipedia corpus (AllCombined.txt)\n",
      "  Sentences: 965,517\n",
      "  Sample: ['april']...\n"
     ]
    }
   ],
   "source": [
    "# Load Wikipedia corpus from text file\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 2: Loading Wikipedia Corpus\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def simple_tokenize(text: str):\n",
    "    \"\"\"Basic tokenizer: lowercase, keep only alphabetic characters and spaces, split on whitespace.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    return text.split()\n",
    "\n",
    "def load_corpus(corpus_path: Path):\n",
    "    \"\"\"Load corpus as list of token lists (one per line).\"\"\"\n",
    "    sentences = []\n",
    "    with corpus_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            tokens = simple_tokenize(line)\n",
    "            if tokens:\n",
    "                sentences.append(tokens)\n",
    "    return sentences\n",
    "\n",
    "corpus_path = Path(CORPUS_PATH)\n",
    "sentences = load_corpus(corpus_path)\n",
    "\n",
    "print(f\"  Source: Wikipedia corpus (AllCombined.txt)\")\n",
    "print(f\"  Sentences: {len(sentences):,}\")\n",
    "if sentences:\n",
    "    print(f\"  Sample: {sentences[0][:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909bca4f",
   "metadata": {},
   "source": [
    "## Step 3: Load Human Behavioral Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02cc8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 3: Loading Human Behavioral Similarity Matrix\n",
      "======================================================================\n",
      "  Source: 4.7 million human triplet judgments\n",
      "  Matrix shape: (1854, 1854)\n",
      "  Similarity range: [0.052, 1.000]\n",
      "  Mean similarity: 0.334\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 3: Loading Human Behavioral Similarity Matrix\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load full behavioral similarity matrix (1854 x 1854 THINGS concepts)\n",
    "behav_data = sio.loadmat(BEHAVIORAL_SIM_PATH)\n",
    "behav_sim_full = behav_data['spose_sim']\n",
    "\n",
    "print(f\"  Source: 4.7 million human triplet judgments\")\n",
    "print(f\"  Matrix shape: {behav_sim_full.shape}\")\n",
    "print(f\"  Similarity range: [{behav_sim_full.min():.3f}, {behav_sim_full.max():.3f}]\")\n",
    "print(f\"  Mean similarity: {behav_sim_full.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd46f1",
   "metadata": {},
   "source": [
    "## Step 4: Load THINGS Concepts & Category Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc07e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 4: Loading THINGS Concepts & Category Labels\n",
      "======================================================================\n",
      "  THINGS concepts: 1854\n",
      "  Category .mat file keys:\n",
      "    category_mat_manual: shape=(1854, 27), dtype=uint8\n",
      "  Using 'category_mat_manual' as category labels (fallback)\n",
      "  Category labels: (1854, 27)\n",
      "  Note: Property ratings not loaded (using concept list only)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 4: Loading THINGS Concepts & Category Labels\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load THINGS concepts (one word per line)\n",
    "def load_things_words(words_path):\n",
    "    \"\"\"Load THINGS word list (one word per line).\"\"\"\n",
    "    words = []\n",
    "    with open(words_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            word = line.strip()\n",
    "            if word:\n",
    "                words.append(word)\n",
    "    return words\n",
    "\n",
    "concepts = load_things_words(THINGS_WORDS_PATH)\n",
    "print(f\"  THINGS concepts: {len(concepts)}\")\n",
    "\n",
    "# Load Category27 labels from .mat file (downstream task)\n",
    "category_data = sio.loadmat(CATEGORY_DATA_PATH)\n",
    "\n",
    "# Debug: show all keys and their shapes\n",
    "print(f\"  Category .mat file keys:\")\n",
    "for key in category_data.keys():\n",
    "    if not key.startswith('__'):\n",
    "        val = category_data[key]\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f\"    {key}: shape={val.shape}, dtype={val.dtype}\")\n",
    "        else:\n",
    "            print(f\"    {key}: type={type(val)}\")\n",
    "\n",
    "# Try to find the category matrix (should be 1854 x 27 or similar)\n",
    "Y_all = None\n",
    "for key in ['typicality', 'category', 'categories', 'Y', 'labels']:\n",
    "    if key in category_data:\n",
    "        arr = category_data[key]\n",
    "        if isinstance(arr, np.ndarray) and len(arr.shape) == 2:\n",
    "            # Check if either dimension is ~27 (categories) and the other is large (concepts)\n",
    "            if arr.shape[0] > 100 or arr.shape[1] > 100:\n",
    "                Y_all = arr.astype(np.float32)\n",
    "                print(f\"  Using '{key}' as category labels\")\n",
    "                break\n",
    "\n",
    "# If not found, try to find the largest 2D array\n",
    "if Y_all is None:\n",
    "    for key in category_data.keys():\n",
    "        if not key.startswith('__'):\n",
    "            arr = category_data[key]\n",
    "            if isinstance(arr, np.ndarray) and len(arr.shape) == 2:\n",
    "                if arr.shape[0] > 100 or arr.shape[1] > 100:\n",
    "                    Y_all = arr.astype(np.float32)\n",
    "                    print(f\"  Using '{key}' as category labels (fallback)\")\n",
    "                    break\n",
    "\n",
    "if Y_all is None:\n",
    "    print(\"  WARNING: Could not find valid category matrix!\")\n",
    "    print(\"  Creating dummy category labels for debugging...\")\n",
    "    # Create dummy labels (all zeros) so the pipeline can at least run\n",
    "    Y_all = np.zeros((len(concepts), 27), dtype=np.float32)\n",
    "\n",
    "# Transpose if needed (should be concepts x categories)\n",
    "if Y_all.shape[0] == 27 and Y_all.shape[1] > 100:\n",
    "    print(f\"  Transposing from {Y_all.shape} to {Y_all.T.shape}\")\n",
    "    Y_all = Y_all.T\n",
    "\n",
    "print(f\"  Category labels: {Y_all.shape}\")\n",
    "\n",
    "# For property ratings, we'll skip for now since the file structure may differ\n",
    "# Create a dummy prop_df for compatibility\n",
    "prop_df = pd.DataFrame(index=concepts)\n",
    "print(f\"  Note: Property ratings not loaded (using concept list only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa45daa",
   "metadata": {},
   "source": [
    "## Step 5: Build Vocabulary & Align Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741294d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 5: Building Vocabulary & Aligning Data\n",
      "======================================================================\n",
      "\n",
      "Building vocabulary (min_count=5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting words: 100%|██████████| 965517/965517 [00:02<00:00, 468630.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Vocabulary size: 112,969\n",
      "  Total tokens: 29,083,496\n",
      "\n",
      "Aligning THINGS concepts with vocabulary...\n",
      "  Matched: 1611 / 1854 concepts\n",
      "  Unmatched: 243 concepts\n",
      "  Sample unmatched: ['airboat', 'anklet', 'applesauce', 'ashtray', 'awning', 'backscratcher', 'bandanna', 'barrette', 'bassinet', 'bat1']\n",
      "  Sample matched: ['aardvark', 'abacus', 'accordion', 'acorn', 'air_conditioner', 'air_mattress', 'air_pump', 'airbag', 'aircraft_carrier', 'airplane']\n",
      "\n",
      "======================================================================\n",
      "ALIGNED DATASET:\n",
      "======================================================================\n",
      "  Valid THINGS concepts: 1611\n",
      "  Category labels Y: (1611, 27)\n",
      "  Similarity matrix: (1611, 1611)\n",
      "  Similarity matrix has 2595321 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 5: Building Vocabulary & Aligning Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build vocabulary from corpus\n",
    "MIN_COUNT = 5\n",
    "print(f\"\\nBuilding vocabulary (min_count={MIN_COUNT})...\")\n",
    "\n",
    "word_counts = Counter()\n",
    "for sent in tqdm(sentences, desc=\"Counting words\"):\n",
    "    word_counts.update(sent)\n",
    "\n",
    "vocab = sorted([w for w, c in word_counts.items() if c >= MIN_COUNT])\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for i, w in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Compute unigram distribution for negative sampling\n",
    "word_freqs = np.array([word_counts[w] for w in vocab], dtype=np.float32)\n",
    "word_freqs = word_freqs ** 0.75\n",
    "word_probs = word_freqs / word_freqs.sum()\n",
    "\n",
    "print(f\"  Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"  Total tokens: {sum(word_counts.values()):,}\")\n",
    "\n",
    "# Helper function to find word in vocabulary\n",
    "def get_word_idx(word, word2idx):\n",
    "    \"\"\"\n",
    "    Try multiple strategies to match THINGS concept to vocabulary word.\n",
    "    THINGS concepts often have underscores (e.g., 'air_conditioner').\n",
    "    Vocabulary has lowercase single words.\n",
    "    \"\"\"\n",
    "    word_lower = word.lower()\n",
    "    \n",
    "    # Strategy 1: Exact match (lowercase)\n",
    "    if word_lower in word2idx:\n",
    "        return word2idx[word_lower]\n",
    "    \n",
    "    # Strategy 2: Replace underscores with nothing (compound word)\n",
    "    no_underscore = word_lower.replace(\"_\", \"\")\n",
    "    if no_underscore in word2idx:\n",
    "        return word2idx[no_underscore]\n",
    "    \n",
    "    # Strategy 3: Take the first word of compound (e.g., \"air\" from \"air_conditioner\")\n",
    "    parts = word_lower.split(\"_\")\n",
    "    if parts[0] in word2idx:\n",
    "        return word2idx[parts[0]]\n",
    "    \n",
    "    # Strategy 4: Take the last word of compound (e.g., \"conditioner\" from \"air_conditioner\")\n",
    "    if len(parts) > 1 and parts[-1] in word2idx:\n",
    "        return word2idx[parts[-1]]\n",
    "    \n",
    "    # Strategy 5: Try each part of the compound\n",
    "    for part in parts:\n",
    "        if part in word2idx:\n",
    "            return word2idx[part]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Align THINGS concepts with vocabulary\n",
    "print(f\"\\nAligning THINGS concepts with vocabulary...\")\n",
    "valid_concepts = []\n",
    "valid_word_indices = []\n",
    "Y_rows = []\n",
    "valid_things_indices = []\n",
    "unmatched_concepts = []\n",
    "\n",
    "for idx, concept in enumerate(concepts):\n",
    "    # Try to find the concept in vocabulary (handle various formats)\n",
    "    word_idx = get_word_idx(concept, word2idx)\n",
    "    if word_idx is None:\n",
    "        unmatched_concepts.append(concept)\n",
    "        continue\n",
    "    # Make sure we have category data for this concept\n",
    "    if idx >= Y_all.shape[0]:\n",
    "        continue\n",
    "    valid_word_indices.append(word_idx)\n",
    "    Y_rows.append(Y_all[idx])\n",
    "    valid_concepts.append(concept)\n",
    "    valid_things_indices.append(idx)\n",
    "\n",
    "# Debug: show matching statistics\n",
    "print(f\"  Matched: {len(valid_concepts)} / {len(concepts)} concepts\")\n",
    "print(f\"  Unmatched: {len(unmatched_concepts)} concepts\")\n",
    "if unmatched_concepts[:10]:\n",
    "    print(f\"  Sample unmatched: {unmatched_concepts[:10]}\")\n",
    "if valid_concepts[:10]:\n",
    "    print(f\"  Sample matched: {valid_concepts[:10]}\")\n",
    "\n",
    "# Safety check\n",
    "if len(valid_concepts) == 0:\n",
    "    raise ValueError(\"No THINGS concepts could be matched to vocabulary! Check word matching logic.\")\n",
    "\n",
    "valid_word_indices = np.array(valid_word_indices)\n",
    "Y = np.stack(Y_rows, axis=0).astype(np.float32)\n",
    "\n",
    "# Extract aligned similarity matrix\n",
    "behav_sim_subset = behav_sim_full[np.ix_(valid_things_indices, valid_things_indices)]\n",
    "behav_sim_target = torch.tensor(behav_sim_subset, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ALIGNED DATASET:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Valid THINGS concepts: {len(valid_concepts)}\")\n",
    "print(f\"  Category labels Y: {Y.shape}\")\n",
    "print(f\"  Similarity matrix: {behav_sim_subset.shape}\")\n",
    "print(f\"  Similarity matrix has {(behav_sim_subset > 0).sum()} non-zero entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b92679",
   "metadata": {},
   "source": [
    "## Step 6: Define Model & Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL CONFIGURATION:\n",
      "======================================================================\n",
      "  Embedding dim: 300\n",
      "  Window size: 5\n",
      "  Negative samples: 5\n",
      "  Batch size: 128\n",
      "  Batches per epoch: 10000\n",
      "  Samples per epoch: ~1,280,000\n",
      "  Epochs: 5\n",
      "  Learning rate: 0.001\n",
      "======================================================================\n",
      "\n",
      "RSR CONFIGURATION (brain_chapter approach):\n",
      "======================================================================\n",
      "  Regularization strength: 0.1\n",
      "  Loss formula: (1-0.1) * L_w2v + 0.1 * L_rsr\n",
      "  RSR loss type: 1 - soft_spearman (rank-based)\n",
      "  RSR frequency: every 1 batch(es)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "class SkipGramWord2Vec(nn.Module):\n",
    "    \"\"\"PyTorch Skip-gram Word2Vec with negative sampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        init_range = 0.5 / embedding_dim\n",
    "        self.target_embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "        self.context_embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "    \n",
    "    def forward(self, targets, contexts):\n",
    "        t_emb = self.target_embeddings(targets)\n",
    "        c_emb = self.context_embeddings(contexts)\n",
    "        return torch.sum(t_emb * c_emb, dim=1)\n",
    "\n",
    "# ============================================================================\n",
    "# Sample pairs randomly as we go\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_sentences(sentences, word2idx):\n",
    "    \"\"\"Convert sentences to index arrays (do once, reuse).\"\"\"\n",
    "    indexed = []\n",
    "    for sent in tqdm(sentences, desc=\"Indexing sentences\"):\n",
    "        indices = [word2idx[w] for w in sent if w in word2idx]\n",
    "        if len(indices) >= 2:\n",
    "            indexed.append(np.array(indices, dtype=np.int32))\n",
    "    return indexed\n",
    "\n",
    "def sample_batch(indexed_sentences, batch_size, window_size, vocab_size, neg_probs_np):\n",
    "    \"\"\"Sample a batch of (target, context, negatives) on-the-fly.\"\"\"\n",
    "    targets = []\n",
    "    contexts = []\n",
    "    \n",
    "    # Sample random sentences and extract pairs\n",
    "    sent_indices = np.random.randint(0, len(indexed_sentences), batch_size * 2)\n",
    "    \n",
    "    for sent_idx in sent_indices:\n",
    "        sent = indexed_sentences[sent_idx]\n",
    "        if len(sent) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Random position in sentence\n",
    "        pos = np.random.randint(0, len(sent))\n",
    "        target = sent[pos]\n",
    "        \n",
    "        # Random context within window\n",
    "        start = max(0, pos - window_size)\n",
    "        end = min(len(sent), pos + window_size + 1)\n",
    "        context_positions = [j for j in range(start, end) if j != pos]\n",
    "        \n",
    "        if context_positions:\n",
    "            ctx_pos = context_positions[np.random.randint(0, len(context_positions))]\n",
    "            targets.append(target)\n",
    "            contexts.append(sent[ctx_pos])\n",
    "        \n",
    "        if len(targets) >= batch_size:\n",
    "            break\n",
    "    \n",
    "    return np.array(targets[:batch_size]), np.array(contexts[:batch_size])\n",
    "\n",
    "\n",
    "def sample_things_batch(indexed_sentences, batch_size, window_size, things_word_indices_set):\n",
    "    \"\"\"\n",
    "    Sample a batch where TARGET words are specifically THINGS concepts.\n",
    "    \n",
    "    This ensures the model sees more training signal for THINGS concepts,\n",
    "    helping them learn better representations that can align with human similarity.\n",
    "    \n",
    "    Args:\n",
    "        indexed_sentences: List of numpy arrays (indexed sentences)\n",
    "        batch_size: Number of (target, context) pairs to sample\n",
    "        window_size: Context window size\n",
    "        things_word_indices_set: Set of word indices that are THINGS concepts\n",
    "    \n",
    "    Returns:\n",
    "        targets, contexts: numpy arrays of word indices\n",
    "    \"\"\"\n",
    "    targets = []\n",
    "    contexts = []\n",
    "    \n",
    "    max_attempts = batch_size * 100  # Prevent infinite loop\n",
    "    attempts = 0\n",
    "    \n",
    "    while len(targets) < batch_size and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        \n",
    "        # Sample a random sentence\n",
    "        sent_idx = np.random.randint(0, len(indexed_sentences))\n",
    "        sent = indexed_sentences[sent_idx]\n",
    "        if len(sent) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Find positions where the word is a THINGS concept\n",
    "        things_positions = [i for i, word_idx in enumerate(sent) \n",
    "                          if word_idx in things_word_indices_set]\n",
    "        \n",
    "        if not things_positions:\n",
    "            continue\n",
    "        \n",
    "        # Random THINGS word position\n",
    "        pos = things_positions[np.random.randint(0, len(things_positions))]\n",
    "        target = sent[pos]\n",
    "        \n",
    "        # Random context within window\n",
    "        start = max(0, pos - window_size)\n",
    "        end = min(len(sent), pos + window_size + 1)\n",
    "        context_positions = [j for j in range(start, end) if j != pos]\n",
    "        \n",
    "        if context_positions:\n",
    "            ctx_pos = context_positions[np.random.randint(0, len(context_positions))]\n",
    "            targets.append(target)\n",
    "            contexts.append(sent[ctx_pos])\n",
    "    \n",
    "    # If we couldn't get enough, just return what we have\n",
    "    actual_size = min(len(targets), batch_size)\n",
    "    return np.array(targets[:actual_size]), np.array(contexts[:actual_size])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "EMBEDDING_DIM = 300\n",
    "WINDOW_SIZE = 5\n",
    "NEG_SAMPLES = 5\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Number of batches per epoch. With batch_size=128, this gives ~1.28M samples/epoch\n",
    "BATCHES_PER_EPOCH = 10000\n",
    "\n",
    "W2V_EPOCHS = 5              \n",
    "W2V_LR = 0.001\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS WEIGHTS (Interpretation 2: Three-component loss)\n",
    "# ============================================================================\n",
    "# L_total = W2V_WEIGHT * L_w2v + THINGS_W2V_WEIGHT * L_things_w2v + RSR_WEIGHT * L_rsr\n",
    "#\n",
    "# Three components:\n",
    "# 1. L_w2v: General vocabulary skip-gram (learns word relationships from corpus)\n",
    "# 2. L_things_w2v: THINGS-focused skip-gram (ensures THINGS words see more training)\n",
    "# 3. L_rsr: Representational similarity regularization (aligns with human judgments)\n",
    "#\n",
    "# Weights should sum to ~1 for interpretability\n",
    "W2V_WEIGHT = 0.7          # General corpus learning\n",
    "THINGS_W2V_WEIGHT = 0.2   # Extra focus on THINGS concepts in corpus\n",
    "RSR_WEIGHT = 0.1          # Human similarity alignment\n",
    "\n",
    "# Batch size for THINGS-focused W2V (can be smaller since fewer concepts)\n",
    "THINGS_BATCH_SIZE = 64\n",
    "\n",
    "# Apply RSR every N batches (1 = every batch like brain_chapter, higher = less frequent)\n",
    "RSR_EVERY_N_BATCHES = 1\n",
    "\n",
    "# ============================================================================\n",
    "# Soft Spearman Correlation (from brain_chapter)\n",
    "# ============================================================================\n",
    "\n",
    "# Number of concept pairs to sample for RSR computation\n",
    "# (Full matrix has ~960K pairs - sampling makes it tractable)\n",
    "RSR_SAMPLE_SIZE = 5000\n",
    "\n",
    "def soft_rank(x, regularization_strength=1.0):\n",
    "    \"\"\"\n",
    "    Differentiable soft ranking using pairwise comparisons with sigmoid.\n",
    "    \n",
    "    For each element, counts how many elements are smaller (soft comparison).\n",
    "    This gives an approximation to the rank that is differentiable.\n",
    "    \n",
    "    Args:\n",
    "        x: 1D tensor of values to rank\n",
    "        regularization_strength: Controls sharpness (higher = sharper ranks)\n",
    "    \n",
    "    Returns:\n",
    "        Soft ranks (1-indexed, differentiable)\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    # For large tensors, use a chunked approach to save memory\n",
    "    if n > 10000:\n",
    "        # For very large n, use a simpler approximation\n",
    "        # Sort indices and use position as rank\n",
    "        _, indices = torch.sort(x)\n",
    "        ranks = torch.zeros_like(x)\n",
    "        ranks[indices] = torch.arange(1, n + 1, dtype=x.dtype, device=x.device)\n",
    "        return ranks\n",
    "    \n",
    "    # Pairwise differences: x[i] - x[j] for all i, j\n",
    "    x_expanded = x.unsqueeze(1)  # (n, 1)\n",
    "    diffs = x_expanded - x.unsqueeze(0)  # (n, n) where [i,j] = x[i] - x[j]\n",
    "    \n",
    "    # Soft comparison: sigmoid of scaled differences\n",
    "    # For each row i, sum of sigmoid(x[i] - x[j]) gives soft count of elements < x[i]\n",
    "    soft_comparisons = torch.sigmoid(regularization_strength * diffs)\n",
    "    \n",
    "    # Sum across columns gives rank\n",
    "    ranks = soft_comparisons.sum(dim=1)\n",
    "    \n",
    "    return ranks\n",
    "\n",
    "\n",
    "def soft_spearman(pred, target, regularization_strength=1.0):\n",
    "    \"\"\"\n",
    "    Differentiable Spearman correlation using soft ranking.\n",
    "    \n",
    "    This is the brain_chapter approach: instead of MSE on similarity matrices,\n",
    "    we compute rank-based correlation which is more robust to scale differences.\n",
    "    \n",
    "    Args:\n",
    "        pred: Model similarity values (sampled pairs)\n",
    "        target: Target similarity values (sampled pairs)  \n",
    "        regularization_strength: Controls sharpness of soft ranking (higher = sharper)\n",
    "    \n",
    "    Returns:\n",
    "        Spearman correlation (higher = more similar, range approximately [-1, 1])\n",
    "    \"\"\"\n",
    "    # Soft rank (differentiable approximation to ranking)\n",
    "    pred_ranked = soft_rank(pred, regularization_strength)\n",
    "    target_ranked = soft_rank(target, regularization_strength)\n",
    "    \n",
    "    # Normalize to zero mean, unit norm (standard correlation formula)\n",
    "    pred_ranked = pred_ranked - pred_ranked.mean()\n",
    "    pred_ranked = pred_ranked / (pred_ranked.norm() + 1e-8)\n",
    "    \n",
    "    target_ranked = target_ranked - target_ranked.mean()\n",
    "    target_ranked = target_ranked / (target_ranked.norm() + 1e-8)\n",
    "    \n",
    "    # Correlation = dot product of normalized vectors\n",
    "    return (pred_ranked * target_ranked).sum()\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"MODEL CONFIGURATION:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Embedding dim: {EMBEDDING_DIM}\")\n",
    "print(f\"  Window size: {WINDOW_SIZE}\")\n",
    "print(f\"  Negative samples: {NEG_SAMPLES}\")\n",
    "print(f\"  General batch size: {BATCH_SIZE}\")\n",
    "print(f\"  THINGS batch size: {THINGS_BATCH_SIZE}\")\n",
    "print(f\"  Batches per epoch: {BATCHES_PER_EPOCH}\")\n",
    "print(f\"  Epochs: {W2V_EPOCHS}\")\n",
    "print(f\"  Learning rate: {W2V_LR}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nTHREE-COMPONENT LOSS (Interpretation 2):\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  L_total = {W2V_WEIGHT} * L_w2v + {THINGS_W2V_WEIGHT} * L_things_w2v + {RSR_WEIGHT} * L_rsr\")\n",
    "print(f\"  \")\n",
    "print(f\"  Components:\")\n",
    "print(f\"    L_w2v ({W2V_WEIGHT}):         General corpus skip-gram\")\n",
    "print(f\"    L_things_w2v ({THINGS_W2V_WEIGHT}):  THINGS-focused skip-gram\")\n",
    "print(f\"    L_rsr ({RSR_WEIGHT}):         Human similarity alignment (soft Spearman)\")\n",
    "print(f\"  \")\n",
    "print(f\"  RSR frequency: every {RSR_EVERY_N_BATCHES} batch(es)\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd14e32",
   "metadata": {},
   "source": [
    "## Step 7: Train VANILLA Word2Vec (Wikipedia Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ca0f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 7: Training VANILLA Word2Vec (Wikipedia Only)\n",
      "======================================================================\n",
      "Using on-the-fly sampling\n",
      "======================================================================\n",
      "\n",
      "Preprocessing sentences (one-time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing sentences: 100%|██████████| 965517/965517 [00:02<00:00, 329115.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Indexed 881,112 sentences\n",
      "\n",
      "Training... (~50,000 iterations total)\n",
      "Expected time: ~100 minutes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 1/5: 100%|██████████| 10000/10000 [01:37<00:00, 102.32it/s, loss=0.4165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Avg Loss: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 2/5: 100%|██████████| 10000/10000 [01:37<00:00, 103.04it/s, loss=0.3788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Avg Loss: 0.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 3/5: 100%|██████████| 10000/10000 [01:37<00:00, 103.00it/s, loss=0.3892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Avg Loss: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 4/5: 100%|██████████| 10000/10000 [01:37<00:00, 102.17it/s, loss=0.3609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Avg Loss: 0.3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 5/5: 100%|██████████| 10000/10000 [01:38<00:00, 101.74it/s, loss=0.3417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Avg Loss: 0.3533\n",
      "\n",
      " Vanilla training complete! Embeddings: (1611, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 7: Training VANILLA Word2Vec (Wikipedia Only)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using on-the-fly sampling\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Preprocess sentences ONCE (convert to indices)\n",
    "print(\"Preprocessing sentences (one-time)...\")\n",
    "indexed_sentences = preprocess_sentences(sentences, word2idx)\n",
    "print(f\"  Indexed {len(indexed_sentences):,} sentences\")\n",
    "\n",
    "# Negative sampling distribution (numpy for fast sampling)\n",
    "neg_probs_np = word_probs\n",
    "neg_probs_torch = torch.tensor(word_probs, device=DEVICE)\n",
    "valid_idx_tensor = torch.LongTensor(valid_word_indices).to(DEVICE)\n",
    "\n",
    "# Pre-allocate tensors for speed\n",
    "pos_labels = torch.ones(BATCH_SIZE, device=DEVICE)\n",
    "neg_labels = torch.zeros(BATCH_SIZE * NEG_SAMPLES, device=DEVICE)\n",
    "\n",
    "# Create VANILLA model\n",
    "vanilla_model = SkipGramWord2Vec(vocab_size, EMBEDDING_DIM).to(DEVICE)\n",
    "vanilla_optimizer = optim.Adam(vanilla_model.parameters(), lr=W2V_LR)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f\"\\nTraining... (~{BATCHES_PER_EPOCH * W2V_EPOCHS:,} iterations total)\")\n",
    "print(f\"Expected time: ~{BATCHES_PER_EPOCH * W2V_EPOCHS // 500} minutes\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(W2V_EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(range(BATCHES_PER_EPOCH), desc=f\"Vanilla Epoch {epoch+1}/{W2V_EPOCHS}\")\n",
    "    for batch_idx in pbar:\n",
    "        # Sample batch on-the-fly (FAST!)\n",
    "        targets_np, contexts_np = sample_batch(\n",
    "            indexed_sentences, BATCH_SIZE, WINDOW_SIZE, vocab_size, neg_probs_np\n",
    "        )\n",
    "        \n",
    "        # To GPU\n",
    "        targets = torch.LongTensor(targets_np).to(DEVICE)\n",
    "        contexts = torch.LongTensor(contexts_np).to(DEVICE)\n",
    "        \n",
    "        # Positive scores\n",
    "        pos_scores = vanilla_model(targets, contexts)\n",
    "        \n",
    "        # Negative samples\n",
    "        neg_contexts = torch.multinomial(neg_probs_torch, len(targets) * NEG_SAMPLES, replacement=True)\n",
    "        neg_targets = targets.repeat_interleave(NEG_SAMPLES)\n",
    "        neg_scores = vanilla_model(neg_targets, neg_contexts)\n",
    "        \n",
    "        # Loss\n",
    "        all_scores = torch.cat([pos_scores, neg_scores])\n",
    "        all_labels = torch.cat([pos_labels[:len(targets)], neg_labels[:len(targets)*NEG_SAMPLES]])\n",
    "        loss = loss_fn(all_scores, all_labels)\n",
    "        \n",
    "        vanilla_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        vanilla_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Avg Loss: {total_loss/BATCHES_PER_EPOCH:.4f}\")\n",
    "\n",
    "# Extract vanilla embeddings\n",
    "X_vanilla = vanilla_model.target_embeddings(valid_idx_tensor).detach().cpu().numpy()\n",
    "print(f\"\\n Vanilla training complete! Embeddings: {X_vanilla.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca9f15",
   "metadata": {},
   "source": [
    "## Step 8: Train RSR Word2Vec (Three-Component Loss)\n",
    "\n",
    "**Interpretation 2**: Uses three loss components to balance general vocabulary learning, THINGS-focused learning, and human similarity alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f567e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 8: Training RSR Word2Vec (Wikipedia + Human Similarity)\n",
      "======================================================================\n",
      "Using brain_chapter approach: soft Spearman + weighted loss combination\n",
      "======================================================================\n",
      "\n",
      "Training with RSR every 1 batch(es)...\n",
      "Loss formula: (1 - 0.1) * L_w2v + 0.1 * L_rsr\n",
      "RSR loss: 1 - soft_spearman(model_sim, target_sim)\n",
      "Sampling 5000 concept pairs per RSR step (from 1,296,855 total)\n",
      "Expected time: ~166 minutes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 1/5: 100%|██████████| 10000/10000 [02:23<00:00, 69.75it/s, w2v=0.4338, rsr=0.0270, ρ=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | W2V: 0.4482 | RSR: 0.0323 | Combined: 0.4066 | Spearman ρ: 0.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 2/5: 100%|██████████| 10000/10000 [02:24<00:00, 69.20it/s, w2v=0.3847, rsr=0.0282, ρ=0.972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | W2V: 0.3858 | RSR: 0.0276 | Combined: 0.3500 | Spearman ρ: 0.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 3/5: 100%|██████████| 10000/10000 [02:24<00:00, 69.12it/s, w2v=0.3855, rsr=0.0244, ρ=0.976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | W2V: 0.3697 | RSR: 0.0270 | Combined: 0.3354 | Spearman ρ: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 4/5: 100%|██████████| 10000/10000 [02:24<00:00, 69.01it/s, w2v=0.3653, rsr=0.0264, ρ=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | W2V: 0.3600 | RSR: 0.0268 | Combined: 0.3266 | Spearman ρ: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 5/5: 100%|██████████| 10000/10000 [02:25<00:00, 68.65it/s, w2v=0.3380, rsr=0.0284, ρ=0.972]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | W2V: 0.3529 | RSR: 0.0267 | Combined: 0.3203 | Spearman ρ: 0.9733\n",
      "\n",
      "✓ RSR training complete! Embeddings: (1611, 300)\n",
      "  Final Spearman correlation with human similarity: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 8: Training RSR Word2Vec (Three-Component Loss)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Interpretation 2: General W2V + THINGS-focused W2V + RSR alignment\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Create RSR model (fresh initialisation with random weights)\n",
    "rsr_model = SkipGramWord2Vec(vocab_size, EMBEDDING_DIM).to(DEVICE)\n",
    "rsr_optimizer = optim.Adam(rsr_model.parameters(), lr=W2V_LR)\n",
    "\n",
    "# Pre-compute all valid upper triangle indices for RSR sampling\n",
    "n_concepts = behav_sim_target.shape[0]\n",
    "all_triu_indices = torch.triu_indices(n_concepts, n_concepts, offset=1, device=DEVICE)\n",
    "total_pairs = all_triu_indices.shape[1]\n",
    "\n",
    "# Create set of THINGS word indices for fast lookup in THINGS-focused batching\n",
    "things_word_indices_set = set(valid_word_indices.tolist())\n",
    "\n",
    "# Pre-allocate labels for THINGS batch size too\n",
    "things_pos_labels = torch.ones(THINGS_BATCH_SIZE, device=DEVICE)\n",
    "things_neg_labels = torch.zeros(THINGS_BATCH_SIZE * NEG_SAMPLES, device=DEVICE)\n",
    "\n",
    "print(f\"Three-component loss:\")\n",
    "print(f\"  L_total = {W2V_WEIGHT} * L_w2v + {THINGS_W2V_WEIGHT} * L_things + {RSR_WEIGHT} * L_rsr\")\n",
    "print(f\"\")\n",
    "print(f\"Components:\")\n",
    "print(f\"  L_w2v:    General skip-gram (batch={BATCH_SIZE})\")\n",
    "print(f\"  L_things: THINGS-focused skip-gram (batch={THINGS_BATCH_SIZE})\")\n",
    "print(f\"  L_rsr:    Soft Spearman alignment (sample={RSR_SAMPLE_SIZE} pairs)\")\n",
    "print(f\"\")\n",
    "print(f\"RSR computed every {RSR_EVERY_N_BATCHES} batch(es)\")\n",
    "print(f\"Expected time: ~{BATCHES_PER_EPOCH * W2V_EPOCHS // 250} minutes\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(W2V_EPOCHS):\n",
    "    total_w2v_loss, total_things_loss, total_rsr_loss, total_combined_loss = 0, 0, 0, 0\n",
    "    total_spearman = 0\n",
    "    rsr_count = 0\n",
    "    \n",
    "    pbar = tqdm(range(BATCHES_PER_EPOCH), desc=f\"RSR Epoch {epoch+1}/{W2V_EPOCHS}\")\n",
    "    for batch_idx in pbar:\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Component 1: General W2V loss (random words from corpus)\n",
    "        # =====================================================================\n",
    "        targets_np, contexts_np = sample_batch(\n",
    "            indexed_sentences, BATCH_SIZE, WINDOW_SIZE, vocab_size, neg_probs_np\n",
    "        )\n",
    "        \n",
    "        targets = torch.LongTensor(targets_np).to(DEVICE)\n",
    "        contexts = torch.LongTensor(contexts_np).to(DEVICE)\n",
    "        \n",
    "        pos_scores = rsr_model(targets, contexts)\n",
    "        neg_contexts = torch.multinomial(neg_probs_torch, len(targets) * NEG_SAMPLES, replacement=True)\n",
    "        neg_targets = targets.repeat_interleave(NEG_SAMPLES)\n",
    "        neg_scores = rsr_model(neg_targets, neg_contexts)\n",
    "        \n",
    "        all_scores = torch.cat([pos_scores, neg_scores])\n",
    "        all_labels = torch.cat([pos_labels[:len(targets)], neg_labels[:len(targets)*NEG_SAMPLES]])\n",
    "        L_w2v = loss_fn(all_scores, all_labels)\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Component 2: THINGS-focused W2V loss (targets are THINGS concepts)\n",
    "        # =====================================================================\n",
    "        things_targets_np, things_contexts_np = sample_things_batch(\n",
    "            indexed_sentences, THINGS_BATCH_SIZE, WINDOW_SIZE, things_word_indices_set\n",
    "        )\n",
    "        \n",
    "        if len(things_targets_np) > 0:\n",
    "            things_targets = torch.LongTensor(things_targets_np).to(DEVICE)\n",
    "            things_contexts = torch.LongTensor(things_contexts_np).to(DEVICE)\n",
    "            \n",
    "            things_pos_scores = rsr_model(things_targets, things_contexts)\n",
    "            things_neg_contexts = torch.multinomial(neg_probs_torch, len(things_targets) * NEG_SAMPLES, replacement=True)\n",
    "            things_neg_targets = things_targets.repeat_interleave(NEG_SAMPLES)\n",
    "            things_neg_scores = rsr_model(things_neg_targets, things_neg_contexts)\n",
    "            \n",
    "            things_all_scores = torch.cat([things_pos_scores, things_neg_scores])\n",
    "            things_all_labels = torch.cat([things_pos_labels[:len(things_targets)], \n",
    "                                           things_neg_labels[:len(things_targets)*NEG_SAMPLES]])\n",
    "            L_things = loss_fn(things_all_scores, things_all_labels)\n",
    "        else:\n",
    "            L_things = torch.tensor(0.0, device=DEVICE)\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Component 3: RSR loss (soft Spearman alignment with human similarity)\n",
    "        # =====================================================================\n",
    "        L_rsr = torch.tensor(0.0, device=DEVICE)\n",
    "        spearman_corr = torch.tensor(0.0, device=DEVICE)\n",
    "        \n",
    "        if batch_idx % RSR_EVERY_N_BATCHES == 0:\n",
    "            # Sample random concept pairs for this RSR step\n",
    "            sample_indices = torch.randperm(total_pairs, device=DEVICE)[:RSR_SAMPLE_SIZE]\n",
    "            sampled_i = all_triu_indices[0, sample_indices]\n",
    "            sampled_j = all_triu_indices[1, sample_indices]\n",
    "            \n",
    "            # Get target similarities for sampled pairs\n",
    "            target_sim_sample = behav_sim_target[sampled_i, sampled_j]\n",
    "            \n",
    "            # Get THINGS concept embeddings and normalize\n",
    "            things_emb = rsr_model.target_embeddings(valid_idx_tensor)\n",
    "            things_emb_norm = F.normalize(things_emb, p=2, dim=1)\n",
    "            \n",
    "            # Compute model similarities for sampled pairs\n",
    "            model_sim_sample = (things_emb_norm[sampled_i] * things_emb_norm[sampled_j]).sum(dim=1)\n",
    "            \n",
    "            # Compute soft Spearman correlation\n",
    "            spearman_corr = soft_spearman(model_sim_sample, target_sim_sample)\n",
    "            \n",
    "            # RSR loss: minimize (1 - correlation)\n",
    "            L_rsr = 1.0 - spearman_corr\n",
    "            \n",
    "            rsr_count += 1\n",
    "            total_spearman += spearman_corr.item()\n",
    "        \n",
    "        # =====================================================================\n",
    "        # Combined loss: Three-component weighted sum\n",
    "        # =====================================================================\n",
    "        L_total = W2V_WEIGHT * L_w2v + THINGS_W2V_WEIGHT * L_things + RSR_WEIGHT * L_rsr\n",
    "        \n",
    "        rsr_optimizer.zero_grad()\n",
    "        L_total.backward()\n",
    "        rsr_optimizer.step()\n",
    "        \n",
    "        total_w2v_loss += L_w2v.item()\n",
    "        total_things_loss += L_things.item()\n",
    "        total_rsr_loss += L_rsr.item()\n",
    "        total_combined_loss += L_total.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            pbar.set_postfix({\n",
    "                'w2v': f'{L_w2v.item():.3f}', \n",
    "                'things': f'{L_things.item():.3f}',\n",
    "                'rsr': f'{L_rsr.item():.3f}',\n",
    "                'ρ': f'{spearman_corr.item():.2f}'\n",
    "            })\n",
    "    \n",
    "    avg_w2v = total_w2v_loss / BATCHES_PER_EPOCH\n",
    "    avg_things = total_things_loss / BATCHES_PER_EPOCH\n",
    "    avg_rsr = total_rsr_loss / max(1, rsr_count)\n",
    "    avg_combined = total_combined_loss / BATCHES_PER_EPOCH\n",
    "    avg_spearman = total_spearman / max(1, rsr_count)\n",
    "    print(f\"Epoch {epoch+1} | W2V: {avg_w2v:.4f} | THINGS: {avg_things:.4f} | RSR: {avg_rsr:.4f} | Total: {avg_combined:.4f} | ρ: {avg_spearman:.4f}\")\n",
    "\n",
    "# Extract RSR embeddings\n",
    "X_rsr = rsr_model.target_embeddings(valid_idx_tensor).detach().cpu().numpy()\n",
    "print(f\"\\n✓ RSR training complete! Embeddings: {X_rsr.shape}\")\n",
    "print(f\"  Final Spearman correlation with human similarity: {avg_spearman:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b60f01",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate on SimLex-999 (Human Similarity Benchmark)\n",
    "\n",
    "SimLex-999 is a gold-standard benchmark for evaluating semantic **similarity** (not just relatedness).\n",
    "\n",
    "We split evaluation into three categories to test generalization:\n",
    "- **Both in THINGS**: Both words were used during RSR training\n",
    "- **One in THINGS**: Only one word was used during RSR training  \n",
    "- **Neither in THINGS**: Neither word was used during RSR training (tests generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c139fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 9: Comparing Models on THINGS Category Prediction\n",
      "======================================================================\n",
      "Task: Predict 27 binary category labels from embeddings\n",
      "Method: Logistic regression with 80/20 train/test split\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESULTS: THINGS Category Prediction (F1 Score)\n",
      "======================================================================\n",
      "  VANILLA (Wikipedia only):     F1 = 0.083 ± 0.111\n",
      "  RSR (Wikipedia + Human Sim):  F1 = 0.577 ± 0.241\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "✓ RSR IMPROVED performance by 0.494 F1 points!\n",
      "  Human similarity judgments help category prediction!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from numpy.linalg import norm\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 9: SimLex-999 Evaluation\")\n",
    "print(\"=\"*70)\n",
    "print(\"Benchmark: SimLex-999 (999 word pairs with human similarity ratings)\")\n",
    "print(\"Metric: Spearman correlation between model similarity and human ratings\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Load SimLex-999\n",
    "# ============================================================================\n",
    "SIMLEX_PATH = \"SimLex-999/SimLex-999.txt\"\n",
    "simlex_df = pd.read_csv(SIMLEX_PATH, sep=\"\\t\")\n",
    "print(f\"Loaded SimLex-999: {len(simlex_df)} word pairs\")\n",
    "print(f\"  Parts of speech: {simlex_df['POS'].value_counts().to_dict()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Create THINGS concept set (lowercase for matching)\n",
    "# ============================================================================\n",
    "things_concepts_lower = set(c.lower() for c in valid_concepts)\n",
    "print(f\"  THINGS concepts (for RSR training): {len(things_concepts_lower)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Categorize each SimLex pair based on THINGS overlap\n",
    "# ============================================================================\n",
    "def categorize_pair(word1, word2, things_set):\n",
    "    \"\"\"Categorize pair based on whether words appear in THINGS.\"\"\"\n",
    "    w1_lower, w2_lower = word1.lower(), word2.lower()\n",
    "    in_things_1 = w1_lower in things_set\n",
    "    in_things_2 = w2_lower in things_set\n",
    "    \n",
    "    if in_things_1 and in_things_2:\n",
    "        return \"both_in_things\"\n",
    "    elif not in_things_1 and not in_things_2:\n",
    "        return \"neither_in_things\"\n",
    "    else:\n",
    "        return \"one_in_things\"\n",
    "\n",
    "simlex_df[\"category\"] = simlex_df.apply(\n",
    "    lambda row: categorize_pair(row[\"word1\"], row[\"word2\"], things_concepts_lower), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"\\nSimLex-999 pair categories:\")\n",
    "for cat, count in simlex_df[\"category\"].value_counts().items():\n",
    "    print(f\"  {cat}: {count} pairs\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Create embedding dictionaries\n",
    "# ============================================================================\n",
    "# Build full vocabulary embedding dicts (not just THINGS concepts)\n",
    "def build_embedding_dict(model, word2idx):\n",
    "    \"\"\"Build word -> embedding dictionary for all words in vocabulary.\"\"\"\n",
    "    embeddings = model.target_embeddings.weight.detach().cpu().numpy()\n",
    "    return {word: embeddings[idx] for word, idx in word2idx.items()}\n",
    "\n",
    "vanilla_emb_dict = build_embedding_dict(vanilla_model, word2idx)\n",
    "rsr_emb_dict = build_embedding_dict(rsr_model, word2idx)\n",
    "\n",
    "print(f\"\\nEmbedding dictionaries built: {len(vanilla_emb_dict):,} words each\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Evaluation function\n",
    "# ============================================================================\n",
    "def evaluate_simlex(embeddings_dict, simlex_df, category=\"all\"):\n",
    "    \"\"\"\n",
    "    Compute Spearman correlation between model cosine similarity and human ratings.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_dict: word -> embedding numpy array\n",
    "        simlex_df: DataFrame with SimLex-999 data\n",
    "        category: \"all\", \"both_in_things\", \"one_in_things\", or \"neither_in_things\"\n",
    "    \n",
    "    Returns:\n",
    "        dict with correlation, p_value, n_pairs, coverage\n",
    "    \"\"\"\n",
    "    if category == \"all\":\n",
    "        subset = simlex_df\n",
    "    else:\n",
    "        subset = simlex_df[simlex_df[\"category\"] == category]\n",
    "    \n",
    "    model_sims = []\n",
    "    human_sims = []\n",
    "    found_pairs = 0\n",
    "    \n",
    "    for _, row in subset.iterrows():\n",
    "        w1, w2 = row[\"word1\"].lower(), row[\"word2\"].lower()\n",
    "        \n",
    "        # Skip if words not in vocabulary\n",
    "        if w1 not in embeddings_dict or w2 not in embeddings_dict:\n",
    "            continue\n",
    "        \n",
    "        found_pairs += 1\n",
    "        \n",
    "        # Cosine similarity\n",
    "        vec1 = embeddings_dict[w1]\n",
    "        vec2 = embeddings_dict[w2]\n",
    "        cos_sim = np.dot(vec1, vec2) / (norm(vec1) * norm(vec2) + 1e-8)\n",
    "        \n",
    "        model_sims.append(cos_sim)\n",
    "        human_sims.append(row[\"SimLex999\"])\n",
    "    \n",
    "    if len(model_sims) < 2:\n",
    "        return {\"correlation\": float(\"nan\"), \"p_value\": float(\"nan\"), \n",
    "                \"n_pairs\": 0, \"coverage\": 0.0}\n",
    "    \n",
    "    corr, pval = spearmanr(model_sims, human_sims)\n",
    "    coverage = found_pairs / len(subset) * 100\n",
    "    \n",
    "    return {\n",
    "        \"correlation\": corr, \n",
    "        \"p_value\": pval, \n",
    "        \"n_pairs\": found_pairs,\n",
    "        \"coverage\": coverage\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 6. Run evaluation for all categories\n",
    "# ============================================================================\n",
    "categories = [\"all\", \"both_in_things\", \"one_in_things\", \"neither_in_things\"]\n",
    "\n",
    "vanilla_results = {}\n",
    "rsr_results = {}\n",
    "\n",
    "for cat in categories:\n",
    "    vanilla_results[cat] = evaluate_simlex(vanilla_emb_dict, simlex_df, cat)\n",
    "    rsr_results[cat] = evaluate_simlex(rsr_emb_dict, simlex_df, cat)\n",
    "\n",
    "# ============================================================================\n",
    "# 7. Print results\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS: SimLex-999 Evaluation (Spearman ρ)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Category':<22} {'N pairs':>8} {'Coverage':>10} {'Vanilla ρ':>12} {'RSR ρ':>12} {'Δ':>10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for cat in categories:\n",
    "    v = vanilla_results[cat]\n",
    "    r = rsr_results[cat]\n",
    "    delta = r[\"correlation\"] - v[\"correlation\"]\n",
    "    \n",
    "    cat_display = cat.replace(\"_\", \" \").title() if cat != \"all\" else \"ALL PAIRS\"\n",
    "    \n",
    "    print(f\"{cat_display:<22} {r['n_pairs']:>8} {r['coverage']:>9.1f}% \"\n",
    "          f\"{v['correlation']:>12.4f} {r['correlation']:>12.4f} {delta:>+10.4f}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 8. Summary interpretation\n",
    "# ============================================================================\n",
    "all_delta = rsr_results[\"all\"][\"correlation\"] - vanilla_results[\"all\"][\"correlation\"]\n",
    "both_delta = rsr_results[\"both_in_things\"][\"correlation\"] - vanilla_results[\"both_in_things\"][\"correlation\"]\n",
    "neither_delta = rsr_results[\"neither_in_things\"][\"correlation\"] - vanilla_results[\"neither_in_things\"][\"correlation\"]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"INTERPRETATION:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if all_delta > 0.01:\n",
    "    print(f\"✓ RSR improved overall SimLex-999 correlation by {all_delta:+.4f}\")\n",
    "else:\n",
    "    print(f\"  Overall change: {all_delta:+.4f}\")\n",
    "\n",
    "if both_delta > 0.02:\n",
    "    print(f\"✓ Strongest improvement for 'both in THINGS' pairs: {both_delta:+.4f}\")\n",
    "    print(f\"  (These words were directly used in RSR training)\")\n",
    "\n",
    "if neither_delta > 0.01:\n",
    "    print(f\"✓ RSR generalizes! Improvement on unseen word pairs: {neither_delta:+.4f}\")\n",
    "elif neither_delta > 0:\n",
    "    print(f\"~ Slight generalization to unseen words: {neither_delta:+.4f}\")\n",
    "else:\n",
    "    print(f\"  No generalization to unseen words: {neither_delta:+.4f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0933bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_vanilla' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array(f1_scores), valid_categories\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Get per-category scores\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m vanilla_f1_per_cat, valid_cats = get_per_category_f1(\u001b[43mX_vanilla\u001b[49m, Y)\n\u001b[32m     28\u001b[39m rsr_f1_per_cat, _ = get_per_category_f1(X_rsr, Y)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Create scatter plot\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X_vanilla' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get per-category F1 scores for both models\n",
    "def get_per_category_f1(X, Y, C=1.0, test_size=0.2, random_state=42):\n",
    "    \"\"\"Get F1 score for each category.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    f1_scores = []\n",
    "    valid_categories = []\n",
    "    \n",
    "    for f in range(Y.shape[1]):\n",
    "        y = Y[:, f]\n",
    "        if np.all(y == y[0]):  # Skip if all same class\n",
    "            continue\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        clf = LogisticRegression(C=C, max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        f1_scores.append(f1_score(y_test, clf.predict(X_test)))\n",
    "        valid_categories.append(f)\n",
    "    \n",
    "    return np.array(f1_scores), valid_categories\n",
    "\n",
    "# Get per-category scores\n",
    "vanilla_f1_per_cat, valid_cats = get_per_category_f1(X_vanilla, Y)\n",
    "rsr_f1_per_cat, _ = get_per_category_f1(X_rsr, Y)\n",
    "\n",
    "# Create scatter plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot points\n",
    "ax.scatter(vanilla_f1_per_cat, rsr_f1_per_cat, s=100, alpha=0.7, \n",
    "           c='#2ecc71', edgecolors='#27ae60', linewidth=2, zorder=3)\n",
    "\n",
    "# Diagonal line (y = x)\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, linewidth=2, label='y = x (no improvement)')\n",
    "\n",
    "# Fill regions\n",
    "ax.fill_between([0, 1], [0, 1], [1, 1], alpha=0.1, color='green', label='RSR wins')\n",
    "ax.fill_between([0, 1], [0, 0], [0, 1], alpha=0.1, color='red', label='Vanilla wins')\n",
    "\n",
    "# Labels and styling\n",
    "ax.set_xlabel('Vanilla Word2Vec (F1)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('RSR Word2Vec (F1)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Per-Category F1: Vanilla vs RSR\\n(Each point = 1 of 27 categories)', fontsize=16, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-0.05, 1.05)\n",
    "ax.set_ylim(-0.05, 1.05)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "\n",
    "# Add annotation\n",
    "n_rsr_wins = np.sum(rsr_f1_per_cat > vanilla_f1_per_cat)\n",
    "n_total = len(vanilla_f1_per_cat)\n",
    "ax.text(0.05, 0.95, f'RSR wins: {n_rsr_wins}/{n_total} categories', \n",
    "        transform=ax.transAxes, fontsize=12, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('results/category_f1_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Plot saved to results/category_f1_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c23e3",
   "metadata": {},
   "source": [
    "## Bonus: Nearest Neighbor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bfa5f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NEAREST NEIGHBOR COMPARISON\n",
      "======================================================================\n",
      "\n",
      "=== 'cat' ===\n",
      "VANILLA: ['pelican', 'zebra', 'chili', 'tree', 'tree_trunk']\n",
      "RSR:     ['chihuahua', 'gorilla', 'meerkat', 'puppy', 'rat']\n",
      "\n",
      "=== 'dog' ===\n",
      "VANILLA: ['weasel', 'lamp', 'cookie', 'cookie_sheet', 'pelican']\n",
      "RSR:     ['kitten', 'poodle', 'meerkat', 'sheep', 'monkey']\n",
      "\n",
      "=== 'car' ===\n",
      "VANILLA: ['car_door', 'car_seat', 'airplane', 'turbine', 'bomb']\n",
      "RSR:     ['car_door', 'car_seat', 'bus', 'limousine', 'hearse']\n",
      "\n",
      "=== 'hammer' ===\n",
      "VANILLA: ['ladle', 'hummingbird', 'raft', 'timer', 'bike']\n",
      "RSR:     ['screwdriver', 'chisel', 'trowel', 'ratchet', 'pliers']\n",
      "\n",
      "=== 'apple' ===\n",
      "VANILLA: ['apple_tree', 'alligator', 'slide', 'jam', 'antenna']\n",
      "RSR:     ['apple_tree', 'pumpkin', 'peach', 'mulberry', 'pineapple']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return float(np.dot(a, b) / (norm(a) * norm(b) + 1e-8))\n",
    "\n",
    "def nearest_neighbors(word, embeddings_dict, k=5):\n",
    "    if word not in embeddings_dict:\n",
    "        return []\n",
    "    vec = embeddings_dict[word]\n",
    "    sims = [(w, cosine_sim(vec, v)) for w, v in embeddings_dict.items() if w != word]\n",
    "    return sorted(sims, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "# Create word -> embedding dicts\n",
    "vanilla_dict = {w: X_vanilla[i] for i, w in enumerate(valid_concepts)}\n",
    "rsr_dict = {w: X_rsr[i] for i, w in enumerate(valid_concepts)}\n",
    "\n",
    "# Compare nearest neighbors\n",
    "test_words = [\"cat\", \"dog\", \"car\", \"hammer\", \"apple\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEAREST NEIGHBOR COMPARISON\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for word in test_words:\n",
    "    if word not in vanilla_dict:\n",
    "        continue\n",
    "    print(f\"=== '{word}' ===\")\n",
    "    print(\"VANILLA:\", [w for w, _ in nearest_neighbors(word, vanilla_dict, 5)])\n",
    "    print(\"RSR:    \", [w for w, _ in nearest_neighbors(word, rsr_dict, 5)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d19538",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c50ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Models saved to results/\n"
     ]
    }
   ],
   "source": [
    "# Save both models for later use\n",
    "import os\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': vanilla_model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'word2idx': word2idx,\n",
    "    'idx2word': idx2word,\n",
    "}, \"results/vanilla_word2vec.pt\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': rsr_model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'word2idx': word2idx,\n",
    "    'idx2word': idx2word,\n",
    "}, \"results/rsr_word2vec.pt\")\n",
    "\n",
    "print(\"✓ Models saved to results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
