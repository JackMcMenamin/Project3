{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c65ea7a",
   "metadata": {},
   "source": [
    "\n",
    "# Word2Vec: Vanilla vs RSR (Human Behavioral Similarity)\n",
    "\n",
    "## Experiment Pipeline\n",
    "\n",
    "**Goal**: Compare two Word2Vec models on downstream category prediction:\n",
    "1. **Vanilla**: Trained ONLY on Wikipedia corpus\n",
    "2. **RSR**: Trained on Wikipedia + Human similarity judgments (4.7M triplets)\n",
    "\n",
    "### Pipeline Steps:\n",
    "1. Load Wikipedia corpus\n",
    "2. Load human behavioral similarity matrix  \n",
    "3. Load THINGS concepts & category labels\n",
    "4. Train Word2Vec **VANILLA** (Wikipedia only)\n",
    "5. Train Word2Vec **RSR** (Wikipedia + human similarity)\n",
    "6. Compare both on THINGS category prediction task\n",
    "\n",
    "### RSR Approach (brain_chapter method)\n",
    "\n",
    "The RSR model uses **Representational Similarity Regularization** adapted from the brain_chapter implementation:\n",
    "\n",
    "- **Loss Function**: Soft Spearman correlation (rank-based, scale-invariant)\n",
    "  - `L_rsr = 1 - soft_spearman(model_similarity, target_similarity)`\n",
    "  \n",
    "- **Loss Combination**: Weighted balance\n",
    "  - `L_total = (1 - α) × L_w2v + α × L_rsr`\n",
    "  - Where `α = REG_STRENGTH` (default: 0.1)\n",
    "\n",
    "- **Efficiency**: Random sampling of concept pairs per batch (default: 5000 pairs)\n",
    "\n",
    "This approach aligns model representations with human behavioral similarity using differentiable ranking, which is more robust than MSE to scale differences between similarity matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab82b3",
   "metadata": {},
   "source": [
    "## Step 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd41a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note: torchsort is the brain_chapter's choice, but it requires C++ compilation.\n",
    "# We use a pure PyTorch soft ranking implementation instead (see soft_rank below).\n",
    "\n",
    "# Configuration\n",
    "BASE_DATA_DIR = \"data\"\n",
    "THINGS_DIR = \"things_similarity\"\n",
    "\n",
    "# Corpus path (text file, one sentence per line)\n",
    "CORPUS_PATH = os.path.join(BASE_DATA_DIR, \"AllCombined.txt\")\n",
    "\n",
    "# THINGS paths\n",
    "THINGS_WORDS_PATH = os.path.join(THINGS_DIR, \"variables\", \"unique_id.txt\")\n",
    "BEHAVIORAL_SIM_PATH = os.path.join(THINGS_DIR, \"data\", \"spose_similarity.mat\")\n",
    "# Try category_mat_manual.mat which likely has the manual category labels\n",
    "CATEGORY_DATA_PATH = os.path.join(THINGS_DIR, \"data\", \"category_mat_manual.mat\")\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37402a11",
   "metadata": {},
   "source": [
    "## Step 2: Load Wikipedia Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b9dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 2: Loading Wikipedia Corpus\n",
      "======================================================================\n",
      "  Source: Wikipedia corpus (AllCombined.txt)\n",
      "  Sentences: 965,517\n",
      "  Sample: ['april']...\n"
     ]
    }
   ],
   "source": [
    "# Load Wikipedia corpus from text file\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 2: Loading Wikipedia Corpus\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def simple_tokenize(text: str):\n",
    "    \"\"\"Basic tokenizer: lowercase, keep only alphabetic characters and spaces, split on whitespace.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
    "    return text.split()\n",
    "\n",
    "def load_corpus(corpus_path: Path):\n",
    "    \"\"\"Load corpus as list of token lists (one per line).\"\"\"\n",
    "    sentences = []\n",
    "    with corpus_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            tokens = simple_tokenize(line)\n",
    "            if tokens:\n",
    "                sentences.append(tokens)\n",
    "    return sentences\n",
    "\n",
    "corpus_path = Path(CORPUS_PATH)\n",
    "sentences = load_corpus(corpus_path)\n",
    "\n",
    "print(f\"  Source: Wikipedia corpus (AllCombined.txt)\")\n",
    "print(f\"  Sentences: {len(sentences):,}\")\n",
    "if sentences:\n",
    "    print(f\"  Sample: {sentences[0][:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909bca4f",
   "metadata": {},
   "source": [
    "## Step 3: Load Human Behavioral Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02cc8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 3: Loading Human Behavioral Similarity Matrix\n",
      "======================================================================\n",
      "  Source: 4.7 million human triplet judgments\n",
      "  Matrix shape: (1854, 1854)\n",
      "  Similarity range: [0.052, 1.000]\n",
      "  Mean similarity: 0.334\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 3: Loading Human Behavioral Similarity Matrix\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load full behavioral similarity matrix (1854 x 1854 THINGS concepts)\n",
    "behav_data = sio.loadmat(BEHAVIORAL_SIM_PATH)\n",
    "behav_sim_full = behav_data['spose_sim']\n",
    "\n",
    "print(f\"  Source: 4.7 million human triplet judgments\")\n",
    "print(f\"  Matrix shape: {behav_sim_full.shape}\")\n",
    "print(f\"  Similarity range: [{behav_sim_full.min():.3f}, {behav_sim_full.max():.3f}]\")\n",
    "print(f\"  Mean similarity: {behav_sim_full.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd46f1",
   "metadata": {},
   "source": [
    "## Step 4: Load THINGS Concepts & Category Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc07e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 4: Loading THINGS Concepts & Category Labels\n",
      "======================================================================\n",
      "  THINGS concepts: 1854\n",
      "  Category .mat file keys:\n",
      "    category_mat_manual: shape=(1854, 27), dtype=uint8\n",
      "  Using 'category_mat_manual' as category labels (fallback)\n",
      "  Category labels: (1854, 27)\n",
      "  Note: Property ratings not loaded (using concept list only)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 4: Loading THINGS Concepts & Category Labels\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load THINGS concepts (one word per line)\n",
    "def load_things_words(words_path):\n",
    "    \"\"\"Load THINGS word list (one word per line).\"\"\"\n",
    "    words = []\n",
    "    with open(words_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            word = line.strip()\n",
    "            if word:\n",
    "                words.append(word)\n",
    "    return words\n",
    "\n",
    "concepts = load_things_words(THINGS_WORDS_PATH)\n",
    "print(f\"  THINGS concepts: {len(concepts)}\")\n",
    "\n",
    "# Load Category27 labels from .mat file (downstream task)\n",
    "category_data = sio.loadmat(CATEGORY_DATA_PATH)\n",
    "\n",
    "# Debug: show all keys and their shapes\n",
    "print(f\"  Category .mat file keys:\")\n",
    "for key in category_data.keys():\n",
    "    if not key.startswith('__'):\n",
    "        val = category_data[key]\n",
    "        if isinstance(val, np.ndarray):\n",
    "            print(f\"    {key}: shape={val.shape}, dtype={val.dtype}\")\n",
    "        else:\n",
    "            print(f\"    {key}: type={type(val)}\")\n",
    "\n",
    "# Try to find the category matrix (should be 1854 x 27 or similar)\n",
    "Y_all = None\n",
    "for key in ['typicality', 'category', 'categories', 'Y', 'labels']:\n",
    "    if key in category_data:\n",
    "        arr = category_data[key]\n",
    "        if isinstance(arr, np.ndarray) and len(arr.shape) == 2:\n",
    "            # Check if either dimension is ~27 (categories) and the other is large (concepts)\n",
    "            if arr.shape[0] > 100 or arr.shape[1] > 100:\n",
    "                Y_all = arr.astype(np.float32)\n",
    "                print(f\"  Using '{key}' as category labels\")\n",
    "                break\n",
    "\n",
    "# If not found, try to find the largest 2D array\n",
    "if Y_all is None:\n",
    "    for key in category_data.keys():\n",
    "        if not key.startswith('__'):\n",
    "            arr = category_data[key]\n",
    "            if isinstance(arr, np.ndarray) and len(arr.shape) == 2:\n",
    "                if arr.shape[0] > 100 or arr.shape[1] > 100:\n",
    "                    Y_all = arr.astype(np.float32)\n",
    "                    print(f\"  Using '{key}' as category labels (fallback)\")\n",
    "                    break\n",
    "\n",
    "if Y_all is None:\n",
    "    print(\"  WARNING: Could not find valid category matrix!\")\n",
    "    print(\"  Creating dummy category labels for debugging...\")\n",
    "    # Create dummy labels (all zeros) so the pipeline can at least run\n",
    "    Y_all = np.zeros((len(concepts), 27), dtype=np.float32)\n",
    "\n",
    "# Transpose if needed (should be concepts x categories)\n",
    "if Y_all.shape[0] == 27 and Y_all.shape[1] > 100:\n",
    "    print(f\"  Transposing from {Y_all.shape} to {Y_all.T.shape}\")\n",
    "    Y_all = Y_all.T\n",
    "\n",
    "print(f\"  Category labels: {Y_all.shape}\")\n",
    "\n",
    "# For property ratings, we'll skip for now since the file structure may differ\n",
    "# Create a dummy prop_df for compatibility\n",
    "prop_df = pd.DataFrame(index=concepts)\n",
    "print(f\"  Note: Property ratings not loaded (using concept list only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa45daa",
   "metadata": {},
   "source": [
    "## Step 5: Build Vocabulary & Align Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741294d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 5: Building Vocabulary & Aligning Data\n",
      "======================================================================\n",
      "\n",
      "Building vocabulary (min_count=5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting words: 100%|██████████| 965517/965517 [00:02<00:00, 468630.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Vocabulary size: 112,969\n",
      "  Total tokens: 29,083,496\n",
      "\n",
      "Aligning THINGS concepts with vocabulary...\n",
      "  Matched: 1611 / 1854 concepts\n",
      "  Unmatched: 243 concepts\n",
      "  Sample unmatched: ['airboat', 'anklet', 'applesauce', 'ashtray', 'awning', 'backscratcher', 'bandanna', 'barrette', 'bassinet', 'bat1']\n",
      "  Sample matched: ['aardvark', 'abacus', 'accordion', 'acorn', 'air_conditioner', 'air_mattress', 'air_pump', 'airbag', 'aircraft_carrier', 'airplane']\n",
      "\n",
      "======================================================================\n",
      "ALIGNED DATASET:\n",
      "======================================================================\n",
      "  Valid THINGS concepts: 1611\n",
      "  Category labels Y: (1611, 27)\n",
      "  Similarity matrix: (1611, 1611)\n",
      "  Similarity matrix has 2595321 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 5: Building Vocabulary & Aligning Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build vocabulary from corpus\n",
    "MIN_COUNT = 5\n",
    "print(f\"\\nBuilding vocabulary (min_count={MIN_COUNT})...\")\n",
    "\n",
    "word_counts = Counter()\n",
    "for sent in tqdm(sentences, desc=\"Counting words\"):\n",
    "    word_counts.update(sent)\n",
    "\n",
    "vocab = sorted([w for w, c in word_counts.items() if c >= MIN_COUNT])\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for i, w in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Compute unigram distribution for negative sampling\n",
    "word_freqs = np.array([word_counts[w] for w in vocab], dtype=np.float32)\n",
    "word_freqs = word_freqs ** 0.75\n",
    "word_probs = word_freqs / word_freqs.sum()\n",
    "\n",
    "print(f\"  Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"  Total tokens: {sum(word_counts.values()):,}\")\n",
    "\n",
    "# Helper function to find word in vocabulary\n",
    "def get_word_idx(word, word2idx):\n",
    "    \"\"\"\n",
    "    Try multiple strategies to match THINGS concept to vocabulary word.\n",
    "    THINGS concepts often have underscores (e.g., 'air_conditioner').\n",
    "    Vocabulary has lowercase single words.\n",
    "    \"\"\"\n",
    "    word_lower = word.lower()\n",
    "    \n",
    "    # Strategy 1: Exact match (lowercase)\n",
    "    if word_lower in word2idx:\n",
    "        return word2idx[word_lower]\n",
    "    \n",
    "    # Strategy 2: Replace underscores with nothing (compound word)\n",
    "    no_underscore = word_lower.replace(\"_\", \"\")\n",
    "    if no_underscore in word2idx:\n",
    "        return word2idx[no_underscore]\n",
    "    \n",
    "    # Strategy 3: Take the first word of compound (e.g., \"air\" from \"air_conditioner\")\n",
    "    parts = word_lower.split(\"_\")\n",
    "    if parts[0] in word2idx:\n",
    "        return word2idx[parts[0]]\n",
    "    \n",
    "    # Strategy 4: Take the last word of compound (e.g., \"conditioner\" from \"air_conditioner\")\n",
    "    if len(parts) > 1 and parts[-1] in word2idx:\n",
    "        return word2idx[parts[-1]]\n",
    "    \n",
    "    # Strategy 5: Try each part of the compound\n",
    "    for part in parts:\n",
    "        if part in word2idx:\n",
    "            return word2idx[part]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Align THINGS concepts with vocabulary\n",
    "print(f\"\\nAligning THINGS concepts with vocabulary...\")\n",
    "valid_concepts = []\n",
    "valid_word_indices = []\n",
    "Y_rows = []\n",
    "valid_things_indices = []\n",
    "unmatched_concepts = []\n",
    "\n",
    "for idx, concept in enumerate(concepts):\n",
    "    # Try to find the concept in vocabulary (handle various formats)\n",
    "    word_idx = get_word_idx(concept, word2idx)\n",
    "    if word_idx is None:\n",
    "        unmatched_concepts.append(concept)\n",
    "        continue\n",
    "    # Make sure we have category data for this concept\n",
    "    if idx >= Y_all.shape[0]:\n",
    "        continue\n",
    "    valid_word_indices.append(word_idx)\n",
    "    Y_rows.append(Y_all[idx])\n",
    "    valid_concepts.append(concept)\n",
    "    valid_things_indices.append(idx)\n",
    "\n",
    "# Debug: show matching statistics\n",
    "print(f\"  Matched: {len(valid_concepts)} / {len(concepts)} concepts\")\n",
    "print(f\"  Unmatched: {len(unmatched_concepts)} concepts\")\n",
    "if unmatched_concepts[:10]:\n",
    "    print(f\"  Sample unmatched: {unmatched_concepts[:10]}\")\n",
    "if valid_concepts[:10]:\n",
    "    print(f\"  Sample matched: {valid_concepts[:10]}\")\n",
    "\n",
    "# Safety check\n",
    "if len(valid_concepts) == 0:\n",
    "    raise ValueError(\"No THINGS concepts could be matched to vocabulary! Check word matching logic.\")\n",
    "\n",
    "valid_word_indices = np.array(valid_word_indices)\n",
    "Y = np.stack(Y_rows, axis=0).astype(np.float32)\n",
    "\n",
    "# Extract aligned similarity matrix\n",
    "behav_sim_subset = behav_sim_full[np.ix_(valid_things_indices, valid_things_indices)]\n",
    "behav_sim_target = torch.tensor(behav_sim_subset, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ALIGNED DATASET:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Valid THINGS concepts: {len(valid_concepts)}\")\n",
    "print(f\"  Category labels Y: {Y.shape}\")\n",
    "print(f\"  Similarity matrix: {behav_sim_subset.shape}\")\n",
    "print(f\"  Similarity matrix has {(behav_sim_subset > 0).sum()} non-zero entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b92679",
   "metadata": {},
   "source": [
    "## Step 6: Define Model & Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4075d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL CONFIGURATION:\n",
      "======================================================================\n",
      "  Embedding dim: 300\n",
      "  Window size: 5\n",
      "  Negative samples: 5\n",
      "  Batch size: 128\n",
      "  Batches per epoch: 10000\n",
      "  Samples per epoch: ~1,280,000\n",
      "  Epochs: 5\n",
      "  Learning rate: 0.001\n",
      "======================================================================\n",
      "\n",
      "RSR CONFIGURATION (brain_chapter approach):\n",
      "======================================================================\n",
      "  Regularization strength: 0.1\n",
      "  Loss formula: (1-0.1) * L_w2v + 0.1 * L_rsr\n",
      "  RSR loss type: 1 - soft_spearman (rank-based)\n",
      "  RSR frequency: every 1 batch(es)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "class SkipGramWord2Vec(nn.Module):\n",
    "    \"\"\"PyTorch Skip-gram Word2Vec with negative sampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        init_range = 0.5 / embedding_dim\n",
    "        self.target_embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "        self.context_embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "    \n",
    "    def forward(self, targets, contexts):\n",
    "        t_emb = self.target_embeddings(targets)\n",
    "        c_emb = self.context_embeddings(contexts)\n",
    "        return torch.sum(t_emb * c_emb, dim=1)\n",
    "\n",
    "# ============================================================================\n",
    "# Sample pairs randomly as we go\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_sentences(sentences, word2idx):\n",
    "    \"\"\"Convert sentences to index arrays (do once, reuse).\"\"\"\n",
    "    indexed = []\n",
    "    for sent in tqdm(sentences, desc=\"Indexing sentences\"):\n",
    "        indices = [word2idx[w] for w in sent if w in word2idx]\n",
    "        if len(indices) >= 2:\n",
    "            indexed.append(np.array(indices, dtype=np.int32))\n",
    "    return indexed\n",
    "\n",
    "def sample_batch(indexed_sentences, batch_size, window_size, vocab_size, neg_probs_np):\n",
    "    \"\"\"Sample a batch of (target, context, negatives) on-the-fly.\"\"\"\n",
    "    targets = []\n",
    "    contexts = []\n",
    "    \n",
    "    # Sample random sentences and extract pairs\n",
    "    sent_indices = np.random.randint(0, len(indexed_sentences), batch_size * 2)\n",
    "    \n",
    "    for sent_idx in sent_indices:\n",
    "        sent = indexed_sentences[sent_idx]\n",
    "        if len(sent) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Random position in sentence\n",
    "        pos = np.random.randint(0, len(sent))\n",
    "        target = sent[pos]\n",
    "        \n",
    "        # Random context within window\n",
    "        start = max(0, pos - window_size)\n",
    "        end = min(len(sent), pos + window_size + 1)\n",
    "        context_positions = [j for j in range(start, end) if j != pos]\n",
    "        \n",
    "        if context_positions:\n",
    "            ctx_pos = context_positions[np.random.randint(0, len(context_positions))]\n",
    "            targets.append(target)\n",
    "            contexts.append(sent[ctx_pos])\n",
    "        \n",
    "        if len(targets) >= batch_size:\n",
    "            break\n",
    "    \n",
    "    return np.array(targets[:batch_size]), np.array(contexts[:batch_size])\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "EMBEDDING_DIM = 300\n",
    "WINDOW_SIZE = 5\n",
    "NEG_SAMPLES = 5\n",
    "\n",
    "# Batch size: Typical values are 32-256 for Word2Vec. Larger batches:\n",
    "# - Pros: Better GPU utilisation, more stable gradients, fewer kernel launches\n",
    "# - Cons: Less frequent updates, may need more epochs, less stochasticity\n",
    "# 128 is a good middle ground - standard in practice and still fast\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Number of batches per epoch. With batch_size=128, this gives ~1.28M samples/epoch\n",
    "# Adjust this to control training time vs coverage (more batches = more samples seen)\n",
    "BATCHES_PER_EPOCH = 10000\n",
    "\n",
    "W2V_EPOCHS = 5              \n",
    "W2V_LR = 0.001\n",
    "\n",
    "# RSR Configuration (brain_chapter approach)\n",
    "# REG_STRENGTH controls the balance between primary task and RSR:\n",
    "#   - 0.0 = No RSR (pure Word2Vec)\n",
    "#   - 0.1 = Light regularization (recommended starting point)\n",
    "#   - 0.5 = Equal weight\n",
    "#   - 0.9 = Heavy RSR regularization\n",
    "# Loss = (1 - REG_STRENGTH) * L_w2v + REG_STRENGTH * L_rsr\n",
    "REG_STRENGTH = 0.1\n",
    "\n",
    "# Apply RSR every N batches (1 = every batch like brain_chapter, higher = less frequent)\n",
    "RSR_EVERY_N_BATCHES = 1\n",
    "\n",
    "# ============================================================================\n",
    "# Soft Spearman Correlation (from brain_chapter)\n",
    "# Pure PyTorch implementation (no C++ compilation needed)\n",
    "# ============================================================================\n",
    "\n",
    "# Number of concept pairs to sample for RSR computation\n",
    "# (Full matrix has ~960K pairs - sampling makes it tractable)\n",
    "RSR_SAMPLE_SIZE = 5000\n",
    "\n",
    "def soft_rank(x, regularization_strength=1.0):\n",
    "    \"\"\"\n",
    "    Differentiable soft ranking using pairwise comparisons with sigmoid.\n",
    "    \n",
    "    For each element, counts how many elements are smaller (soft comparison).\n",
    "    This gives an approximation to the rank that is differentiable.\n",
    "    \n",
    "    Args:\n",
    "        x: 1D tensor of values to rank\n",
    "        regularization_strength: Controls sharpness (higher = sharper ranks)\n",
    "    \n",
    "    Returns:\n",
    "        Soft ranks (1-indexed, differentiable)\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    # For large tensors, use a chunked approach to save memory\n",
    "    if n > 10000:\n",
    "        # For very large n, use a simpler approximation\n",
    "        # Sort indices and use position as rank\n",
    "        _, indices = torch.sort(x)\n",
    "        ranks = torch.zeros_like(x)\n",
    "        ranks[indices] = torch.arange(1, n + 1, dtype=x.dtype, device=x.device)\n",
    "        return ranks\n",
    "    \n",
    "    # Pairwise differences: x[i] - x[j] for all i, j\n",
    "    x_expanded = x.unsqueeze(1)  # (n, 1)\n",
    "    diffs = x_expanded - x.unsqueeze(0)  # (n, n) where [i,j] = x[i] - x[j]\n",
    "    \n",
    "    # Soft comparison: sigmoid of scaled differences\n",
    "    # For each row i, sum of sigmoid(x[i] - x[j]) gives soft count of elements < x[i]\n",
    "    soft_comparisons = torch.sigmoid(regularization_strength * diffs)\n",
    "    \n",
    "    # Sum across columns gives rank\n",
    "    ranks = soft_comparisons.sum(dim=1)\n",
    "    \n",
    "    return ranks\n",
    "\n",
    "\n",
    "def soft_spearman(pred, target, regularization_strength=1.0):\n",
    "    \"\"\"\n",
    "    Differentiable Spearman correlation using soft ranking.\n",
    "    \n",
    "    This is the brain_chapter approach: instead of MSE on similarity matrices,\n",
    "    we compute rank-based correlation which is more robust to scale differences.\n",
    "    \n",
    "    Args:\n",
    "        pred: Model similarity values (sampled pairs)\n",
    "        target: Target similarity values (sampled pairs)  \n",
    "        regularization_strength: Controls sharpness of soft ranking (higher = sharper)\n",
    "    \n",
    "    Returns:\n",
    "        Spearman correlation (higher = more similar, range approximately [-1, 1])\n",
    "    \"\"\"\n",
    "    # Soft rank (differentiable approximation to ranking)\n",
    "    pred_ranked = soft_rank(pred, regularization_strength)\n",
    "    target_ranked = soft_rank(target, regularization_strength)\n",
    "    \n",
    "    # Normalize to zero mean, unit norm (standard correlation formula)\n",
    "    pred_ranked = pred_ranked - pred_ranked.mean()\n",
    "    pred_ranked = pred_ranked / (pred_ranked.norm() + 1e-8)\n",
    "    \n",
    "    target_ranked = target_ranked - target_ranked.mean()\n",
    "    target_ranked = target_ranked / (target_ranked.norm() + 1e-8)\n",
    "    \n",
    "    # Correlation = dot product of normalized vectors\n",
    "    return (pred_ranked * target_ranked).sum()\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"MODEL CONFIGURATION:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Embedding dim: {EMBEDDING_DIM}\")\n",
    "print(f\"  Window size: {WINDOW_SIZE}\")\n",
    "print(f\"  Negative samples: {NEG_SAMPLES}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Batches per epoch: {BATCHES_PER_EPOCH}\")\n",
    "print(f\"  Samples per epoch: ~{BATCH_SIZE * BATCHES_PER_EPOCH:,}\")\n",
    "print(f\"  Epochs: {W2V_EPOCHS}\")\n",
    "print(f\"  Learning rate: {W2V_LR}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nRSR CONFIGURATION (brain_chapter approach):\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Regularization strength: {REG_STRENGTH}\")\n",
    "print(f\"  Loss formula: (1-{REG_STRENGTH}) * L_w2v + {REG_STRENGTH} * L_rsr\")\n",
    "print(f\"  RSR loss type: 1 - soft_spearman (rank-based)\")\n",
    "print(f\"  RSR frequency: every {RSR_EVERY_N_BATCHES} batch(es)\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd14e32",
   "metadata": {},
   "source": [
    "## Step 7: Train VANILLA Word2Vec (Wikipedia Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ca0f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 7: Training VANILLA Word2Vec (Wikipedia Only)\n",
      "======================================================================\n",
      "Using on-the-fly sampling\n",
      "======================================================================\n",
      "\n",
      "Preprocessing sentences (one-time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing sentences: 100%|██████████| 965517/965517 [00:02<00:00, 329115.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Indexed 881,112 sentences\n",
      "\n",
      "Training... (~50,000 iterations total)\n",
      "Expected time: ~100 minutes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 1/5: 100%|██████████| 10000/10000 [01:37<00:00, 102.32it/s, loss=0.4165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Avg Loss: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 2/5: 100%|██████████| 10000/10000 [01:37<00:00, 103.04it/s, loss=0.3788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Avg Loss: 0.3859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 3/5: 100%|██████████| 10000/10000 [01:37<00:00, 103.00it/s, loss=0.3892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Avg Loss: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 4/5: 100%|██████████| 10000/10000 [01:37<00:00, 102.17it/s, loss=0.3609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Avg Loss: 0.3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 5/5: 100%|██████████| 10000/10000 [01:38<00:00, 101.74it/s, loss=0.3417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Avg Loss: 0.3533\n",
      "\n",
      " Vanilla training complete! Embeddings: (1611, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 7: Training VANILLA Word2Vec (Wikipedia Only)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using on-the-fly sampling\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Preprocess sentences ONCE (convert to indices)\n",
    "print(\"Preprocessing sentences (one-time)...\")\n",
    "indexed_sentences = preprocess_sentences(sentences, word2idx)\n",
    "print(f\"  Indexed {len(indexed_sentences):,} sentences\")\n",
    "\n",
    "# Negative sampling distribution (numpy for fast sampling)\n",
    "neg_probs_np = word_probs\n",
    "neg_probs_torch = torch.tensor(word_probs, device=DEVICE)\n",
    "valid_idx_tensor = torch.LongTensor(valid_word_indices).to(DEVICE)\n",
    "\n",
    "# Pre-allocate tensors for speed\n",
    "pos_labels = torch.ones(BATCH_SIZE, device=DEVICE)\n",
    "neg_labels = torch.zeros(BATCH_SIZE * NEG_SAMPLES, device=DEVICE)\n",
    "\n",
    "# Create VANILLA model\n",
    "vanilla_model = SkipGramWord2Vec(vocab_size, EMBEDDING_DIM).to(DEVICE)\n",
    "vanilla_optimizer = optim.Adam(vanilla_model.parameters(), lr=W2V_LR)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f\"\\nTraining... (~{BATCHES_PER_EPOCH * W2V_EPOCHS:,} iterations total)\")\n",
    "print(f\"Expected time: ~{BATCHES_PER_EPOCH * W2V_EPOCHS // 500} minutes\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(W2V_EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(range(BATCHES_PER_EPOCH), desc=f\"Vanilla Epoch {epoch+1}/{W2V_EPOCHS}\")\n",
    "    for batch_idx in pbar:\n",
    "        # Sample batch on-the-fly (FAST!)\n",
    "        targets_np, contexts_np = sample_batch(\n",
    "            indexed_sentences, BATCH_SIZE, WINDOW_SIZE, vocab_size, neg_probs_np\n",
    "        )\n",
    "        \n",
    "        # To GPU\n",
    "        targets = torch.LongTensor(targets_np).to(DEVICE)\n",
    "        contexts = torch.LongTensor(contexts_np).to(DEVICE)\n",
    "        \n",
    "        # Positive scores\n",
    "        pos_scores = vanilla_model(targets, contexts)\n",
    "        \n",
    "        # Negative samples\n",
    "        neg_contexts = torch.multinomial(neg_probs_torch, len(targets) * NEG_SAMPLES, replacement=True)\n",
    "        neg_targets = targets.repeat_interleave(NEG_SAMPLES)\n",
    "        neg_scores = vanilla_model(neg_targets, neg_contexts)\n",
    "        \n",
    "        # Loss\n",
    "        all_scores = torch.cat([pos_scores, neg_scores])\n",
    "        all_labels = torch.cat([pos_labels[:len(targets)], neg_labels[:len(targets)*NEG_SAMPLES]])\n",
    "        loss = loss_fn(all_scores, all_labels)\n",
    "        \n",
    "        vanilla_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        vanilla_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Avg Loss: {total_loss/BATCHES_PER_EPOCH:.4f}\")\n",
    "\n",
    "# Extract vanilla embeddings\n",
    "X_vanilla = vanilla_model.target_embeddings(valid_idx_tensor).detach().cpu().numpy()\n",
    "print(f\"\\n Vanilla training complete! Embeddings: {X_vanilla.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca9f15",
   "metadata": {},
   "source": [
    "## Step 8: Train RSR Word2Vec (Wikipedia + Human Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f567e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 8: Training RSR Word2Vec (Wikipedia + Human Similarity)\n",
      "======================================================================\n",
      "Using brain_chapter approach: soft Spearman + weighted loss combination\n",
      "======================================================================\n",
      "\n",
      "Training with RSR every 1 batch(es)...\n",
      "Loss formula: (1 - 0.1) * L_w2v + 0.1 * L_rsr\n",
      "RSR loss: 1 - soft_spearman(model_sim, target_sim)\n",
      "Sampling 5000 concept pairs per RSR step (from 1,296,855 total)\n",
      "Expected time: ~166 minutes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 1/5: 100%|██████████| 10000/10000 [02:23<00:00, 69.75it/s, w2v=0.4338, rsr=0.0270, ρ=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | W2V: 0.4482 | RSR: 0.0323 | Combined: 0.4066 | Spearman ρ: 0.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 2/5: 100%|██████████| 10000/10000 [02:24<00:00, 69.20it/s, w2v=0.3847, rsr=0.0282, ρ=0.972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | W2V: 0.3858 | RSR: 0.0276 | Combined: 0.3500 | Spearman ρ: 0.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 3/5: 100%|██████████| 10000/10000 [02:24<00:00, 69.12it/s, w2v=0.3855, rsr=0.0244, ρ=0.976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | W2V: 0.3697 | RSR: 0.0270 | Combined: 0.3354 | Spearman ρ: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 4/5: 100%|██████████| 10000/10000 [02:24<00:00, 69.01it/s, w2v=0.3653, rsr=0.0264, ρ=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | W2V: 0.3600 | RSR: 0.0268 | Combined: 0.3266 | Spearman ρ: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 5/5: 100%|██████████| 10000/10000 [02:25<00:00, 68.65it/s, w2v=0.3380, rsr=0.0284, ρ=0.972]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | W2V: 0.3529 | RSR: 0.0267 | Combined: 0.3203 | Spearman ρ: 0.9733\n",
      "\n",
      "✓ RSR training complete! Embeddings: (1611, 300)\n",
      "  Final Spearman correlation with human similarity: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 8: Training RSR Word2Vec (Wikipedia + Human Similarity)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using brain_chapter approach: soft Spearman + weighted loss combination\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Create RSR model (fresh initialisation with random weights)\n",
    "rsr_model = SkipGramWord2Vec(vocab_size, EMBEDDING_DIM).to(DEVICE)\n",
    "rsr_optimizer = optim.Adam(rsr_model.parameters(), lr=W2V_LR)\n",
    "\n",
    "# Pre-compute all valid upper triangle indices for sampling\n",
    "# Full matrix has n*(n-1)/2 pairs = ~960K pairs for 1386 concepts\n",
    "n_concepts = behav_sim_target.shape[0]\n",
    "all_triu_indices = torch.triu_indices(n_concepts, n_concepts, offset=1, device=DEVICE)\n",
    "total_pairs = all_triu_indices.shape[1]\n",
    "\n",
    "print(f\"Training with RSR every {RSR_EVERY_N_BATCHES} batch(es)...\")\n",
    "print(f\"Loss formula: (1 - {REG_STRENGTH}) * L_w2v + {REG_STRENGTH} * L_rsr\")\n",
    "print(f\"RSR loss: 1 - soft_spearman(model_sim, target_sim)\")\n",
    "print(f\"Sampling {RSR_SAMPLE_SIZE} concept pairs per RSR step (from {total_pairs:,} total)\")\n",
    "print(f\"Expected time: ~{BATCHES_PER_EPOCH * W2V_EPOCHS // 300} minutes\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(W2V_EPOCHS):\n",
    "    total_w2v_loss, total_rsr_loss, total_combined_loss = 0, 0, 0\n",
    "    total_spearman = 0\n",
    "    rsr_count = 0\n",
    "    \n",
    "    pbar = tqdm(range(BATCHES_PER_EPOCH), desc=f\"RSR Epoch {epoch+1}/{W2V_EPOCHS}\")\n",
    "    for batch_idx in pbar:\n",
    "        # Sample batch on-the-fly\n",
    "        targets_np, contexts_np = sample_batch(\n",
    "            indexed_sentences, BATCH_SIZE, WINDOW_SIZE, vocab_size, neg_probs_np\n",
    "        )\n",
    "        \n",
    "        targets = torch.LongTensor(targets_np).to(DEVICE)\n",
    "        contexts = torch.LongTensor(contexts_np).to(DEVICE)\n",
    "        \n",
    "        # Skip-gram loss\n",
    "        pos_scores = rsr_model(targets, contexts)\n",
    "        neg_contexts = torch.multinomial(neg_probs_torch, len(targets) * NEG_SAMPLES, replacement=True)\n",
    "        neg_targets = targets.repeat_interleave(NEG_SAMPLES)\n",
    "        neg_scores = rsr_model(neg_targets, neg_contexts)\n",
    "        \n",
    "        all_scores = torch.cat([pos_scores, neg_scores])\n",
    "        all_labels = torch.cat([pos_labels[:len(targets)], neg_labels[:len(targets)*NEG_SAMPLES]])\n",
    "        L_w2v = loss_fn(all_scores, all_labels)\n",
    "        \n",
    "        # RSR loss using soft Spearman (brain_chapter approach)\n",
    "        L_rsr = torch.tensor(0.0, device=DEVICE)\n",
    "        spearman_corr = torch.tensor(0.0, device=DEVICE)\n",
    "        \n",
    "        if batch_idx % RSR_EVERY_N_BATCHES == 0:\n",
    "            # Sample random concept pairs for this RSR step\n",
    "            sample_indices = torch.randperm(total_pairs, device=DEVICE)[:RSR_SAMPLE_SIZE]\n",
    "            sampled_i = all_triu_indices[0, sample_indices]\n",
    "            sampled_j = all_triu_indices[1, sample_indices]\n",
    "            \n",
    "            # Get target similarities for sampled pairs\n",
    "            target_sim_sample = behav_sim_target[sampled_i, sampled_j]\n",
    "            \n",
    "            # Get THINGS concept embeddings and normalize\n",
    "            things_emb = rsr_model.target_embeddings(valid_idx_tensor)\n",
    "            things_emb_norm = F.normalize(things_emb, p=2, dim=1)\n",
    "            \n",
    "            # Compute model similarities for sampled pairs\n",
    "            # sim(i, j) = dot(emb[i], emb[j]) for normalized embeddings\n",
    "            model_sim_sample = (things_emb_norm[sampled_i] * things_emb_norm[sampled_j]).sum(dim=1)\n",
    "            \n",
    "            # Compute soft Spearman correlation (brain_chapter approach)\n",
    "            spearman_corr = soft_spearman(model_sim_sample, target_sim_sample)\n",
    "            \n",
    "            # RSR loss: we want to maximize correlation, so minimize (1 - correlation)\n",
    "            L_rsr = 1.0 - spearman_corr\n",
    "            \n",
    "            rsr_count += 1\n",
    "            total_spearman += spearman_corr.item()\n",
    "        \n",
    "        # Combined loss: brain_chapter weighted balance approach\n",
    "        # L_total = (1 - reg_strength) * L_w2v + reg_strength * L_rsr\n",
    "        L_total = (1.0 - REG_STRENGTH) * L_w2v + REG_STRENGTH * L_rsr\n",
    "        \n",
    "        rsr_optimizer.zero_grad()\n",
    "        L_total.backward()\n",
    "        rsr_optimizer.step()\n",
    "        \n",
    "        total_w2v_loss += L_w2v.item()\n",
    "        total_rsr_loss += L_rsr.item()\n",
    "        total_combined_loss += L_total.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            pbar.set_postfix({\n",
    "                'w2v': f'{L_w2v.item():.4f}', \n",
    "                'rsr': f'{L_rsr.item():.4f}',\n",
    "                'ρ': f'{spearman_corr.item():.3f}'\n",
    "            })\n",
    "    \n",
    "    avg_w2v = total_w2v_loss / BATCHES_PER_EPOCH\n",
    "    avg_rsr = total_rsr_loss / max(1, rsr_count)\n",
    "    avg_combined = total_combined_loss / BATCHES_PER_EPOCH\n",
    "    avg_spearman = total_spearman / max(1, rsr_count)\n",
    "    print(f\"Epoch {epoch+1} | W2V: {avg_w2v:.4f} | RSR: {avg_rsr:.4f} | Combined: {avg_combined:.4f} | Spearman ρ: {avg_spearman:.4f}\")\n",
    "\n",
    "# Extract RSR embeddings\n",
    "X_rsr = rsr_model.target_embeddings(valid_idx_tensor).detach().cpu().numpy()\n",
    "print(f\"\\n✓ RSR training complete! Embeddings: {X_rsr.shape}\")\n",
    "print(f\"  Final Spearman correlation with human similarity: {avg_spearman:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Compare on Downstream Task (THINGS Category Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 9: Comparing Models on THINGS Category Prediction\n",
      "======================================================================\n",
      "Task: Predict 27 binary category labels from embeddings\n",
      "Method: Logistic regression with 80/20 train/test split\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESULTS: THINGS Category Prediction (F1 Score)\n",
      "======================================================================\n",
      "  VANILLA (Wikipedia only):     F1 = 0.083 ± 0.111\n",
      "  RSR (Wikipedia + Human Sim):  F1 = 0.577 ± 0.241\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "✓ RSR IMPROVED performance by 0.494 F1 points!\n",
      "  Human similarity judgments help category prediction!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 9: Comparing Models on THINGS Category Prediction\")\n",
    "print(\"=\"*70)\n",
    "print(\"Task: Predict 27 binary category labels from embeddings\")\n",
    "print(\"Method: Logistic regression with 80/20 train/test split\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def evaluate_embeddings(X, Y, C=1.0, test_size=0.2, random_state=42):\n",
    "    \"\"\"Evaluate embeddings on category prediction. Returns mean F1.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    f1_scores = []\n",
    "    for f in range(Y.shape[1]):\n",
    "        y = Y[:, f]\n",
    "        if np.all(y == y[0]):\n",
    "            continue\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        clf = LogisticRegression(C=C, max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        f1_scores.append(f1_score(y_test, clf.predict(X_test)))\n",
    "    \n",
    "    return float(np.mean(f1_scores)), float(np.std(f1_scores))\n",
    "\n",
    "# Evaluate both models\n",
    "vanilla_f1, vanilla_std = evaluate_embeddings(X_vanilla, Y)\n",
    "rsr_f1, rsr_std = evaluate_embeddings(X_rsr, Y)\n",
    "\n",
    "# Results\n",
    "print(\"=\"*70)\n",
    "print(\"RESULTS: THINGS Category Prediction (F1 Score)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  VANILLA (Wikipedia only):     F1 = {vanilla_f1:.3f} ± {vanilla_std:.3f}\")\n",
    "print(f\"  RSR (Wikipedia + Human Sim):  F1 = {rsr_f1:.3f} ± {rsr_std:.3f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "delta = rsr_f1 - vanilla_f1\n",
    "print(f\"\\n{'='*70}\")\n",
    "if delta > 0.01:\n",
    "    print(f\"✓ RSR IMPROVED performance by {delta:.3f} F1 points!\")\n",
    "    print(f\"  Human similarity judgments help category prediction!\")\n",
    "elif delta > 0:\n",
    "    print(f\"~ Slight improvement: Δ = {delta:.3f} F1\")\n",
    "else:\n",
    "    print(f\"✗ No improvement: Δ = {delta:.3f} F1\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Nearest Neighbor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NEAREST NEIGHBOR COMPARISON\n",
      "======================================================================\n",
      "\n",
      "=== 'cat' ===\n",
      "VANILLA: ['pelican', 'zebra', 'chili', 'tree', 'tree_trunk']\n",
      "RSR:     ['chihuahua', 'gorilla', 'meerkat', 'puppy', 'rat']\n",
      "\n",
      "=== 'dog' ===\n",
      "VANILLA: ['weasel', 'lamp', 'cookie', 'cookie_sheet', 'pelican']\n",
      "RSR:     ['kitten', 'poodle', 'meerkat', 'sheep', 'monkey']\n",
      "\n",
      "=== 'car' ===\n",
      "VANILLA: ['car_door', 'car_seat', 'airplane', 'turbine', 'bomb']\n",
      "RSR:     ['car_door', 'car_seat', 'bus', 'limousine', 'hearse']\n",
      "\n",
      "=== 'hammer' ===\n",
      "VANILLA: ['ladle', 'hummingbird', 'raft', 'timer', 'bike']\n",
      "RSR:     ['screwdriver', 'chisel', 'trowel', 'ratchet', 'pliers']\n",
      "\n",
      "=== 'apple' ===\n",
      "VANILLA: ['apple_tree', 'alligator', 'slide', 'jam', 'antenna']\n",
      "RSR:     ['apple_tree', 'pumpkin', 'peach', 'mulberry', 'pineapple']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return float(np.dot(a, b) / (norm(a) * norm(b) + 1e-8))\n",
    "\n",
    "def nearest_neighbors(word, embeddings_dict, k=5):\n",
    "    if word not in embeddings_dict:\n",
    "        return []\n",
    "    vec = embeddings_dict[word]\n",
    "    sims = [(w, cosine_sim(vec, v)) for w, v in embeddings_dict.items() if w != word]\n",
    "    return sorted(sims, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "# Create word -> embedding dicts\n",
    "vanilla_dict = {w: X_vanilla[i] for i, w in enumerate(valid_concepts)}\n",
    "rsr_dict = {w: X_rsr[i] for i, w in enumerate(valid_concepts)}\n",
    "\n",
    "# Compare nearest neighbors\n",
    "test_words = [\"cat\", \"dog\", \"car\", \"hammer\", \"apple\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEAREST NEIGHBOR COMPARISON\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for word in test_words:\n",
    "    if word not in vanilla_dict:\n",
    "        continue\n",
    "    print(f\"=== '{word}' ===\")\n",
    "    print(\"VANILLA:\", [w for w, _ in nearest_neighbors(word, vanilla_dict, 5)])\n",
    "    print(\"RSR:    \", [w for w, _ in nearest_neighbors(word, rsr_dict, 5)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Models saved to results/\n"
     ]
    }
   ],
   "source": [
    "# Save both models for later use\n",
    "import os\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': vanilla_model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'word2idx': word2idx,\n",
    "    'idx2word': idx2word,\n",
    "}, \"results/vanilla_word2vec.pt\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': rsr_model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'word2idx': word2idx,\n",
    "    'idx2word': idx2word,\n",
    "}, \"results/rsr_word2vec.pt\")\n",
    "\n",
    "print(\"✓ Models saved to results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
