{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Word2Vec: Vanilla vs RSR (Human Behavioral Similarity)\n",
    "\n",
    "## Experiment Pipeline\n",
    "\n",
    "**Goal**: Compare two Word2Vec models on downstream category prediction:\n",
    "1. **Vanilla**: Trained ONLY on Wikipedia corpus\n",
    "2. **RSR**: Trained on Wikipedia + Human similarity judgments (4.7M triplets)\n",
    "\n",
    "### Pipeline Steps:\n",
    "1. Load Wikipedia corpus\n",
    "2. Load human behavioral similarity matrix  \n",
    "3. Load THINGS concepts & category labels\n",
    "4. Train Word2Vec **VANILLA** (Wikipedia only)\n",
    "5. Train Word2Vec **RSR** (Wikipedia + human similarity)\n",
    "6. Compare both on THINGS category prediction task\n",
    "\n",
    "### RSR Approach (brain_chapter method)\n",
    "\n",
    "The RSR model uses **Representational Similarity Regularization** adapted from the brain_chapter implementation:\n",
    "\n",
    "- **Loss Function**: Soft Spearman correlation (rank-based, scale-invariant)\n",
    "  - `L_rsr = 1 - soft_spearman(model_similarity, target_similarity)`\n",
    "  \n",
    "- **Loss Combination**: Weighted balance\n",
    "  - `L_total = (1 - α) × L_w2v + α × L_rsr`\n",
    "  - Where `α = REG_STRENGTH` (default: 0.1)\n",
    "\n",
    "- **Efficiency**: Random sampling of concept pairs per batch (default: 5000 pairs)\n",
    "\n",
    "This approach aligns model representations with human behavioral similarity using differentiable ranking, which is more robust than MSE to scale differences between similarity matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Note: torchsort is the brain_chapter's choice, but it requires C++ compilation.\n",
    "# We use a pure PyTorch soft ranking implementation instead (see soft_rank below).\n",
    "\n",
    "# Configuration\n",
    "BASE_DATA_DIR = \"data\"\n",
    "\n",
    "# THINGS paths\n",
    "THINGS_CONCEPTS_PATH = os.path.join(BASE_DATA_DIR, \"02_object-level\", \"_concepts-metadata_things.tsv\")\n",
    "PROPERTY_RATINGS_PATH = os.path.join(BASE_DATA_DIR, \"02_object-level\", \"_property-ratings.tsv\")\n",
    "THINGS_FEATURES_PATH = os.path.join(BASE_DATA_DIR, \"03_category-level\", \"category27_manual.tsv\")\n",
    "\n",
    "# Behavioral similarity path\n",
    "BEHAVIORAL_SIM_PATH = os.path.join(BASE_DATA_DIR, \"osfstorage-archive\", \"data\", \"spose_similarity.mat\")\n",
    "\n",
    "# Preprocessed corpus path\n",
    "CORPUS_PATH = os.path.join(BASE_DATA_DIR, \"simplewiki_preprocessed.pkl\")\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Wikipedia Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 2: Loading Wikipedia Corpus\n",
      "======================================================================\n",
      "  Source: Simple Wikipedia (preprocessed)\n",
      "  Sentences: 1,688,343\n",
      "  Sample: ['april', 'apr', 'is', 'the', 'fourth', 'month', 'of', 'the', 'year', 'in']...\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed Simple Wikipedia corpus\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 2: Loading Wikipedia Corpus\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "with open(CORPUS_PATH, 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "\n",
    "print(f\"  Source: Simple Wikipedia (preprocessed)\")\n",
    "print(f\"  Sentences: {len(sentences):,}\")\n",
    "print(f\"  Sample: {sentences[0][:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Human Behavioral Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 3: Loading Human Behavioral Similarity Matrix\n",
      "======================================================================\n",
      "  Source: 4.7 million human triplet judgments\n",
      "  Matrix shape: (1854, 1854)\n",
      "  Similarity range: [0.052, 1.000]\n",
      "  Mean similarity: 0.334\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 3: Loading Human Behavioral Similarity Matrix\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load full behavioral similarity matrix (1854 x 1854 THINGS concepts)\n",
    "behav_data = sio.loadmat(BEHAVIORAL_SIM_PATH)\n",
    "behav_sim_full = behav_data['spose_sim']\n",
    "\n",
    "print(f\"  Source: 4.7 million human triplet judgments\")\n",
    "print(f\"  Matrix shape: {behav_sim_full.shape}\")\n",
    "print(f\"  Similarity range: [{behav_sim_full.min():.3f}, {behav_sim_full.max():.3f}]\")\n",
    "print(f\"  Mean similarity: {behav_sim_full.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load THINGS Concepts & Category Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 4: Loading THINGS Concepts & Category Labels\n",
      "======================================================================\n",
      "  THINGS concepts: 1854\n",
      "  Category labels: (1854, 27) (27 binary categories)\n",
      "  Property ratings: (1823, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 4: Loading THINGS Concepts & Category Labels\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load THINGS concepts\n",
    "concepts_df = pd.read_csv(THINGS_CONCEPTS_PATH, sep=\"\\t\")\n",
    "concepts = concepts_df[\"Word\"].tolist()\n",
    "print(f\"  THINGS concepts: {len(concepts)}\")\n",
    "\n",
    "# Load Category27 labels (downstream task)\n",
    "cats_df = pd.read_csv(THINGS_FEATURES_PATH, sep=\"\\t\")\n",
    "feature_cols = cats_df.columns.tolist()\n",
    "Y_all = cats_df[feature_cols].values.astype(np.float32)\n",
    "print(f\"  Category labels: {Y_all.shape} (27 binary categories)\")\n",
    "\n",
    "# Load property ratings (for filtering)\n",
    "prop_df_raw = pd.read_csv(PROPERTY_RATINGS_PATH, sep=\"\\t\")\n",
    "all_num_cols = prop_df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "sem_cols = [c for c in all_num_cols if c.endswith(\"_mean\") and not c.startswith(\"N_\") and \"work_time\" not in c]\n",
    "prop_df = prop_df_raw.groupby(\"Word\")[sem_cols].mean()\n",
    "print(f\"  Property ratings: {prop_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Build Vocabulary & Align Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 5: Building Vocabulary & Aligning Data\n",
      "======================================================================\n",
      "\n",
      "Building vocabulary (min_count=5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting words: 100%|██████████| 1688343/1688343 [00:02<00:00, 758686.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Vocabulary size: 104,458\n",
      "  Total tokens: 27,446,826\n",
      "\n",
      "Aligning THINGS concepts with vocabulary...\n",
      "\n",
      "======================================================================\n",
      "ALIGNED DATASET:\n",
      "======================================================================\n",
      "  Valid THINGS concepts: 1386\n",
      "  Category labels Y: (1386, 27)\n",
      "  Similarity matrix: (1386, 1386)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 5: Building Vocabulary & Aligning Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build vocabulary from corpus\n",
    "MIN_COUNT = 5\n",
    "print(f\"\\nBuilding vocabulary (min_count={MIN_COUNT})...\")\n",
    "\n",
    "word_counts = Counter()\n",
    "for sent in tqdm(sentences, desc=\"Counting words\"):\n",
    "    word_counts.update(sent)\n",
    "\n",
    "vocab = sorted([w for w, c in word_counts.items() if c >= MIN_COUNT])\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for i, w in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Compute unigram distribution for negative sampling\n",
    "word_freqs = np.array([word_counts[w] for w in vocab], dtype=np.float32)\n",
    "word_freqs = word_freqs ** 0.75\n",
    "word_probs = word_freqs / word_freqs.sum()\n",
    "\n",
    "print(f\"  Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"  Total tokens: {sum(word_counts.values()):,}\")\n",
    "\n",
    "# Helper function to find word in vocabulary\n",
    "def get_word_idx(word, word2idx):\n",
    "    candidates = [word, word.lower(), word.replace(\" \", \"_\"), \n",
    "                  word.lower().replace(\" \", \"_\"), word.replace(\" \", \"\"), \n",
    "                  word.lower().replace(\" \", \"\")]\n",
    "    for token in candidates:\n",
    "        if token in word2idx:\n",
    "            return word2idx[token]\n",
    "    return None\n",
    "\n",
    "# Align THINGS concepts with vocabulary\n",
    "print(f\"\\nAligning THINGS concepts with vocabulary...\")\n",
    "valid_concepts = []\n",
    "valid_word_indices = []\n",
    "Y_rows = []\n",
    "valid_things_indices = []\n",
    "\n",
    "for idx, concept in enumerate(concepts):\n",
    "    if concept not in prop_df.index:\n",
    "        continue\n",
    "    word_idx = get_word_idx(concept, word2idx)\n",
    "    if word_idx is None:\n",
    "        continue\n",
    "    valid_word_indices.append(word_idx)\n",
    "    Y_rows.append(Y_all[idx])\n",
    "    valid_concepts.append(concept)\n",
    "    valid_things_indices.append(idx)\n",
    "\n",
    "valid_word_indices = np.array(valid_word_indices)\n",
    "Y = np.stack(Y_rows, axis=0).astype(np.float32)\n",
    "\n",
    "# Extract aligned similarity matrix\n",
    "behav_sim_subset = behav_sim_full[np.ix_(valid_things_indices, valid_things_indices)]\n",
    "behav_sim_target = torch.tensor(behav_sim_subset, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ALIGNED DATASET:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Valid THINGS concepts: {len(valid_concepts)}\")\n",
    "print(f\"  Category labels Y: {Y.shape}\")\n",
    "print(f\"  Similarity matrix: {behav_sim_subset.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Model & Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL CONFIGURATION:\n",
      "======================================================================\n",
      "  Embedding dim: 300\n",
      "  Window size: 5\n",
      "  Negative samples: 5\n",
      "  Batch size: 128\n",
      "  Batches per epoch: 10000\n",
      "  Samples per epoch: ~1,280,000\n",
      "  Epochs: 5\n",
      "  Learning rate: 0.001\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "class SkipGramWord2Vec(nn.Module):\n",
    "    \"\"\"PyTorch Skip-gram Word2Vec with negative sampling.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.target_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        init_range = 0.5 / embedding_dim\n",
    "        self.target_embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "        self.context_embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "    \n",
    "    def forward(self, targets, contexts):\n",
    "        t_emb = self.target_embeddings(targets)\n",
    "        c_emb = self.context_embeddings(contexts)\n",
    "        return torch.sum(t_emb * c_emb, dim=1)\n",
    "\n",
    "# ============================================================================\n",
    "# Sample pairs randomly as we go\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_sentences(sentences, word2idx):\n",
    "    \"\"\"Convert sentences to index arrays (do once, reuse).\"\"\"\n",
    "    indexed = []\n",
    "    for sent in tqdm(sentences, desc=\"Indexing sentences\"):\n",
    "        indices = [word2idx[w] for w in sent if w in word2idx]\n",
    "        if len(indices) >= 2:\n",
    "            indexed.append(np.array(indices, dtype=np.int32))\n",
    "    return indexed\n",
    "\n",
    "def sample_batch(indexed_sentences, batch_size, window_size, vocab_size, neg_probs_np):\n",
    "    \"\"\"Sample a batch of (target, context, negatives) on-the-fly.\"\"\"\n",
    "    targets = []\n",
    "    contexts = []\n",
    "    \n",
    "    # Sample random sentences and extract pairs\n",
    "    sent_indices = np.random.randint(0, len(indexed_sentences), batch_size * 2)\n",
    "    \n",
    "    for sent_idx in sent_indices:\n",
    "        sent = indexed_sentences[sent_idx]\n",
    "        if len(sent) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Random position in sentence\n",
    "        pos = np.random.randint(0, len(sent))\n",
    "        target = sent[pos]\n",
    "        \n",
    "        # Random context within window\n",
    "        start = max(0, pos - window_size)\n",
    "        end = min(len(sent), pos + window_size + 1)\n",
    "        context_positions = [j for j in range(start, end) if j != pos]\n",
    "        \n",
    "        if context_positions:\n",
    "            ctx_pos = context_positions[np.random.randint(0, len(context_positions))]\n",
    "            targets.append(target)\n",
    "            contexts.append(sent[ctx_pos])\n",
    "        \n",
    "        if len(targets) >= batch_size:\n",
    "            break\n",
    "    \n",
    "    return np.array(targets[:batch_size]), np.array(contexts[:batch_size])\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "EMBEDDING_DIM = 300\n",
    "WINDOW_SIZE = 5\n",
    "NEG_SAMPLES = 5\n",
    "\n",
    "# Batch size: Typical values are 32-256 for Word2Vec. Larger batches:\n",
    "# - Pros: Better GPU utilisation, more stable gradients, fewer kernel launches\n",
    "# - Cons: Less frequent updates, may need more epochs, less stochasticity\n",
    "# 128 is a good middle ground - standard in practice and still fast\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Number of batches per epoch. With batch_size=128, this gives ~1.28M samples/epoch\n",
    "# Adjust this to control training time vs coverage (more batches = more samples seen)\n",
    "BATCHES_PER_EPOCH = 10000\n",
    "\n",
    "W2V_EPOCHS = 5              \n",
    "W2V_LR = 0.001\n",
    "\n",
    "# RSR Configuration (brain_chapter approach)\n",
    "# REG_STRENGTH controls the balance between primary task and RSR:\n",
    "#   - 0.0 = No RSR (pure Word2Vec)\n",
    "#   - 0.1 = Light regularization (recommended starting point)\n",
    "#   - 0.5 = Equal weight\n",
    "#   - 0.9 = Heavy RSR regularization\n",
    "# Loss = (1 - REG_STRENGTH) * L_w2v + REG_STRENGTH * L_rsr\n",
    "REG_STRENGTH = 0.1\n",
    "\n",
    "# Apply RSR every N batches (1 = every batch like brain_chapter, higher = less frequent)\n",
    "RSR_EVERY_N_BATCHES = 1\n",
    "\n",
    "# ============================================================================\n",
    "# Soft Spearman Correlation (from brain_chapter)\n",
    "# Pure PyTorch implementation (no C++ compilation needed)\n",
    "# ============================================================================\n",
    "\n",
    "# Number of concept pairs to sample for RSR computation\n",
    "# (Full matrix has ~960K pairs - sampling makes it tractable)\n",
    "RSR_SAMPLE_SIZE = 5000\n",
    "\n",
    "def soft_rank(x, regularization_strength=1.0):\n",
    "    \"\"\"\n",
    "    Differentiable soft ranking using pairwise comparisons with sigmoid.\n",
    "    \n",
    "    For each element, counts how many elements are smaller (soft comparison).\n",
    "    This gives an approximation to the rank that is differentiable.\n",
    "    \n",
    "    Args:\n",
    "        x: 1D tensor of values to rank\n",
    "        regularization_strength: Controls sharpness (higher = sharper ranks)\n",
    "    \n",
    "    Returns:\n",
    "        Soft ranks (1-indexed, differentiable)\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    # For large tensors, use a chunked approach to save memory\n",
    "    if n > 10000:\n",
    "        # For very large n, use a simpler approximation\n",
    "        # Sort indices and use position as rank\n",
    "        _, indices = torch.sort(x)\n",
    "        ranks = torch.zeros_like(x)\n",
    "        ranks[indices] = torch.arange(1, n + 1, dtype=x.dtype, device=x.device)\n",
    "        return ranks\n",
    "    \n",
    "    # Pairwise differences: x[i] - x[j] for all i, j\n",
    "    x_expanded = x.unsqueeze(1)  # (n, 1)\n",
    "    diffs = x_expanded - x.unsqueeze(0)  # (n, n) where [i,j] = x[i] - x[j]\n",
    "    \n",
    "    # Soft comparison: sigmoid of scaled differences\n",
    "    # For each row i, sum of sigmoid(x[i] - x[j]) gives soft count of elements < x[i]\n",
    "    soft_comparisons = torch.sigmoid(regularization_strength * diffs)\n",
    "    \n",
    "    # Sum across columns gives rank\n",
    "    ranks = soft_comparisons.sum(dim=1)\n",
    "    \n",
    "    return ranks\n",
    "\n",
    "\n",
    "def soft_spearman(pred, target, regularization_strength=1.0):\n",
    "    \"\"\"\n",
    "    Differentiable Spearman correlation using soft ranking.\n",
    "    \n",
    "    This is the brain_chapter approach: instead of MSE on similarity matrices,\n",
    "    we compute rank-based correlation which is more robust to scale differences.\n",
    "    \n",
    "    Args:\n",
    "        pred: Model similarity values (sampled pairs)\n",
    "        target: Target similarity values (sampled pairs)  \n",
    "        regularization_strength: Controls sharpness of soft ranking (higher = sharper)\n",
    "    \n",
    "    Returns:\n",
    "        Spearman correlation (higher = more similar, range approximately [-1, 1])\n",
    "    \"\"\"\n",
    "    # Soft rank (differentiable approximation to ranking)\n",
    "    pred_ranked = soft_rank(pred, regularization_strength)\n",
    "    target_ranked = soft_rank(target, regularization_strength)\n",
    "    \n",
    "    # Normalize to zero mean, unit norm (standard correlation formula)\n",
    "    pred_ranked = pred_ranked - pred_ranked.mean()\n",
    "    pred_ranked = pred_ranked / (pred_ranked.norm() + 1e-8)\n",
    "    \n",
    "    target_ranked = target_ranked - target_ranked.mean()\n",
    "    target_ranked = target_ranked / (target_ranked.norm() + 1e-8)\n",
    "    \n",
    "    # Correlation = dot product of normalized vectors\n",
    "    return (pred_ranked * target_ranked).sum()\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"MODEL CONFIGURATION:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Embedding dim: {EMBEDDING_DIM}\")\n",
    "print(f\"  Window size: {WINDOW_SIZE}\")\n",
    "print(f\"  Negative samples: {NEG_SAMPLES}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Batches per epoch: {BATCHES_PER_EPOCH}\")\n",
    "print(f\"  Samples per epoch: ~{BATCH_SIZE * BATCHES_PER_EPOCH:,}\")\n",
    "print(f\"  Epochs: {W2V_EPOCHS}\")\n",
    "print(f\"  Learning rate: {W2V_LR}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nRSR CONFIGURATION (brain_chapter approach):\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Regularization strength: {REG_STRENGTH}\")\n",
    "print(f\"  Loss formula: (1-{REG_STRENGTH}) * L_w2v + {REG_STRENGTH} * L_rsr\")\n",
    "print(f\"  RSR loss type: 1 - soft_spearman (rank-based)\")\n",
    "print(f\"  RSR frequency: every {RSR_EVERY_N_BATCHES} batch(es)\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train VANILLA Word2Vec (Wikipedia Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 7: Training VANILLA Word2Vec (Wikipedia Only)\n",
      "======================================================================\n",
      "Using on-the-fly sampling\n",
      "======================================================================\n",
      "\n",
      "Preprocessing sentences (one-time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing sentences: 100%|██████████| 1688343/1688343 [00:03<00:00, 525042.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Indexed 1,687,117 sentences\n",
      "\n",
      "Training... (~50,000 iterations total)\n",
      "Expected time: ~100 minutes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vanilla Epoch 1/5:  33%|███▎      | 3303/10000 [00:31<01:03, 106.16it/s, loss=0.4513]"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 7: Training VANILLA Word2Vec (Wikipedia Only)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using on-the-fly sampling\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Preprocess sentences ONCE (convert to indices)\n",
    "print(\"Preprocessing sentences (one-time)...\")\n",
    "indexed_sentences = preprocess_sentences(sentences, word2idx)\n",
    "print(f\"  Indexed {len(indexed_sentences):,} sentences\")\n",
    "\n",
    "# Negative sampling distribution (numpy for fast sampling)\n",
    "neg_probs_np = word_probs\n",
    "neg_probs_torch = torch.tensor(word_probs, device=DEVICE)\n",
    "valid_idx_tensor = torch.LongTensor(valid_word_indices).to(DEVICE)\n",
    "\n",
    "# Pre-allocate tensors for speed\n",
    "pos_labels = torch.ones(BATCH_SIZE, device=DEVICE)\n",
    "neg_labels = torch.zeros(BATCH_SIZE * NEG_SAMPLES, device=DEVICE)\n",
    "\n",
    "# Create VANILLA model\n",
    "vanilla_model = SkipGramWord2Vec(vocab_size, EMBEDDING_DIM).to(DEVICE)\n",
    "vanilla_optimizer = optim.Adam(vanilla_model.parameters(), lr=W2V_LR)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f\"\\nTraining... (~{BATCHES_PER_EPOCH * W2V_EPOCHS:,} iterations total)\")\n",
    "print(f\"Expected time: ~{BATCHES_PER_EPOCH * W2V_EPOCHS // 500} minutes\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(W2V_EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(range(BATCHES_PER_EPOCH), desc=f\"Vanilla Epoch {epoch+1}/{W2V_EPOCHS}\")\n",
    "    for batch_idx in pbar:\n",
    "        # Sample batch on-the-fly (FAST!)\n",
    "        targets_np, contexts_np = sample_batch(\n",
    "            indexed_sentences, BATCH_SIZE, WINDOW_SIZE, vocab_size, neg_probs_np\n",
    "        )\n",
    "        \n",
    "        # To GPU\n",
    "        targets = torch.LongTensor(targets_np).to(DEVICE)\n",
    "        contexts = torch.LongTensor(contexts_np).to(DEVICE)\n",
    "        \n",
    "        # Positive scores\n",
    "        pos_scores = vanilla_model(targets, contexts)\n",
    "        \n",
    "        # Negative samples\n",
    "        neg_contexts = torch.multinomial(neg_probs_torch, len(targets) * NEG_SAMPLES, replacement=True)\n",
    "        neg_targets = targets.repeat_interleave(NEG_SAMPLES)\n",
    "        neg_scores = vanilla_model(neg_targets, neg_contexts)\n",
    "        \n",
    "        # Loss\n",
    "        all_scores = torch.cat([pos_scores, neg_scores])\n",
    "        all_labels = torch.cat([pos_labels[:len(targets)], neg_labels[:len(targets)*NEG_SAMPLES]])\n",
    "        loss = loss_fn(all_scores, all_labels)\n",
    "        \n",
    "        vanilla_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        vanilla_optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Avg Loss: {total_loss/BATCHES_PER_EPOCH:.4f}\")\n",
    "\n",
    "# Extract vanilla embeddings\n",
    "X_vanilla = vanilla_model.target_embeddings(valid_idx_tensor).detach().cpu().numpy()\n",
    "print(f\"\\n Vanilla training complete! Embeddings: {X_vanilla.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train RSR Word2Vec (Wikipedia + Human Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 8: Training RSR Word2Vec (Wikipedia + Human Similarity)\n",
      "======================================================================\n",
      "Using FAST on-the-fly sampling + RSR regularization\n",
      "======================================================================\n",
      "\n",
      "Training with RSR every 50 batches...\n",
      "Expected time: ~125 minutes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 1/5: 100%|██████████| 10000/10000 [06:58<00:00, 23.92it/s, w2v=0.3580, rsr=0.0050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | W2V: 0.3789 | RSR: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 2/5: 100%|██████████| 10000/10000 [05:44<00:00, 29.02it/s, w2v=0.3482, rsr=0.0054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | W2V: 0.3526 | RSR: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 3/5: 100%|██████████| 10000/10000 [04:09<00:00, 40.07it/s, w2v=0.3447, rsr=0.0054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | W2V: 0.3461 | RSR: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 4/5: 100%|██████████| 10000/10000 [04:09<00:00, 40.06it/s, w2v=0.3444, rsr=0.0054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | W2V: 0.3425 | RSR: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RSR Epoch 5/5: 100%|██████████| 10000/10000 [04:12<00:00, 39.56it/s, w2v=0.3371, rsr=0.0054]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | W2V: 0.3401 | RSR: 0.0054\n",
      "\n",
      "✓ RSR training complete! Embeddings: (1386, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 8: Training RSR Word2Vec (Wikipedia + Human Similarity)\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using brain_chapter approach: soft Spearman + weighted loss combination\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Create RSR model (fresh initialisation with random weights)\n",
    "rsr_model = SkipGramWord2Vec(vocab_size, EMBEDDING_DIM).to(DEVICE)\n",
    "rsr_optimizer = optim.Adam(rsr_model.parameters(), lr=W2V_LR)\n",
    "\n",
    "# Pre-compute all valid upper triangle indices for sampling\n",
    "# Full matrix has n*(n-1)/2 pairs = ~960K pairs for 1386 concepts\n",
    "n_concepts = behav_sim_target.shape[0]\n",
    "all_triu_indices = torch.triu_indices(n_concepts, n_concepts, offset=1, device=DEVICE)\n",
    "total_pairs = all_triu_indices.shape[1]\n",
    "\n",
    "print(f\"Training with RSR every {RSR_EVERY_N_BATCHES} batch(es)...\")\n",
    "print(f\"Loss formula: (1 - {REG_STRENGTH}) * L_w2v + {REG_STRENGTH} * L_rsr\")\n",
    "print(f\"RSR loss: 1 - soft_spearman(model_sim, target_sim)\")\n",
    "print(f\"Sampling {RSR_SAMPLE_SIZE} concept pairs per RSR step (from {total_pairs:,} total)\")\n",
    "print(f\"Expected time: ~{BATCHES_PER_EPOCH * W2V_EPOCHS // 300} minutes\\n\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(W2V_EPOCHS):\n",
    "    total_w2v_loss, total_rsr_loss, total_combined_loss = 0, 0, 0\n",
    "    total_spearman = 0\n",
    "    rsr_count = 0\n",
    "    \n",
    "    pbar = tqdm(range(BATCHES_PER_EPOCH), desc=f\"RSR Epoch {epoch+1}/{W2V_EPOCHS}\")\n",
    "    for batch_idx in pbar:\n",
    "        # Sample batch on-the-fly\n",
    "        targets_np, contexts_np = sample_batch(\n",
    "            indexed_sentences, BATCH_SIZE, WINDOW_SIZE, vocab_size, neg_probs_np\n",
    "        )\n",
    "        \n",
    "        targets = torch.LongTensor(targets_np).to(DEVICE)\n",
    "        contexts = torch.LongTensor(contexts_np).to(DEVICE)\n",
    "        \n",
    "        # Skip-gram loss\n",
    "        pos_scores = rsr_model(targets, contexts)\n",
    "        neg_contexts = torch.multinomial(neg_probs_torch, len(targets) * NEG_SAMPLES, replacement=True)\n",
    "        neg_targets = targets.repeat_interleave(NEG_SAMPLES)\n",
    "        neg_scores = rsr_model(neg_targets, neg_contexts)\n",
    "        \n",
    "        all_scores = torch.cat([pos_scores, neg_scores])\n",
    "        all_labels = torch.cat([pos_labels[:len(targets)], neg_labels[:len(targets)*NEG_SAMPLES]])\n",
    "        L_w2v = loss_fn(all_scores, all_labels)\n",
    "        \n",
    "        # RSR loss using soft Spearman (brain_chapter approach)\n",
    "        L_rsr = torch.tensor(0.0, device=DEVICE)\n",
    "        spearman_corr = torch.tensor(0.0, device=DEVICE)\n",
    "        \n",
    "        if batch_idx % RSR_EVERY_N_BATCHES == 0:\n",
    "            # Sample random concept pairs for this RSR step\n",
    "            sample_indices = torch.randperm(total_pairs, device=DEVICE)[:RSR_SAMPLE_SIZE]\n",
    "            sampled_i = all_triu_indices[0, sample_indices]\n",
    "            sampled_j = all_triu_indices[1, sample_indices]\n",
    "            \n",
    "            # Get target similarities for sampled pairs\n",
    "            target_sim_sample = behav_sim_target[sampled_i, sampled_j]\n",
    "            \n",
    "            # Get THINGS concept embeddings and normalize\n",
    "            things_emb = rsr_model.target_embeddings(valid_idx_tensor)\n",
    "            things_emb_norm = F.normalize(things_emb, p=2, dim=1)\n",
    "            \n",
    "            # Compute model similarities for sampled pairs\n",
    "            # sim(i, j) = dot(emb[i], emb[j]) for normalized embeddings\n",
    "            model_sim_sample = (things_emb_norm[sampled_i] * things_emb_norm[sampled_j]).sum(dim=1)\n",
    "            \n",
    "            # Compute soft Spearman correlation (brain_chapter approach)\n",
    "            spearman_corr = soft_spearman(model_sim_sample, target_sim_sample)\n",
    "            \n",
    "            # RSR loss: we want to maximize correlation, so minimize (1 - correlation)\n",
    "            L_rsr = 1.0 - spearman_corr\n",
    "            \n",
    "            rsr_count += 1\n",
    "            total_spearman += spearman_corr.item()\n",
    "        \n",
    "        # Combined loss: brain_chapter weighted balance approach\n",
    "        # L_total = (1 - reg_strength) * L_w2v + reg_strength * L_rsr\n",
    "        L_total = (1.0 - REG_STRENGTH) * L_w2v + REG_STRENGTH * L_rsr\n",
    "        \n",
    "        rsr_optimizer.zero_grad()\n",
    "        L_total.backward()\n",
    "        rsr_optimizer.step()\n",
    "        \n",
    "        total_w2v_loss += L_w2v.item()\n",
    "        total_rsr_loss += L_rsr.item()\n",
    "        total_combined_loss += L_total.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            pbar.set_postfix({\n",
    "                'w2v': f'{L_w2v.item():.4f}', \n",
    "                'rsr': f'{L_rsr.item():.4f}',\n",
    "                'ρ': f'{spearman_corr.item():.3f}'\n",
    "            })\n",
    "    \n",
    "    avg_w2v = total_w2v_loss / BATCHES_PER_EPOCH\n",
    "    avg_rsr = total_rsr_loss / max(1, rsr_count)\n",
    "    avg_combined = total_combined_loss / BATCHES_PER_EPOCH\n",
    "    avg_spearman = total_spearman / max(1, rsr_count)\n",
    "    print(f\"Epoch {epoch+1} | W2V: {avg_w2v:.4f} | RSR: {avg_rsr:.4f} | Combined: {avg_combined:.4f} | Spearman ρ: {avg_spearman:.4f}\")\n",
    "\n",
    "# Extract RSR embeddings\n",
    "X_rsr = rsr_model.target_embeddings(valid_idx_tensor).detach().cpu().numpy()\n",
    "print(f\"\\n✓ RSR training complete! Embeddings: {X_rsr.shape}\")\n",
    "print(f\"  Final Spearman correlation with human similarity: {avg_spearman:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Compare on Downstream Task (THINGS Category Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 9: Comparing Models on THINGS Category Prediction\n",
      "======================================================================\n",
      "Task: Predict 27 binary category labels from embeddings\n",
      "Method: Logistic regression with 80/20 train/test split\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESULTS: THINGS Category Prediction (F1 Score)\n",
      "======================================================================\n",
      "  VANILLA (Wikipedia only):     F1 = 0.340 ± 0.260\n",
      "  RSR (Wikipedia + Human Sim):  F1 = 0.573 ± 0.253\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "✓ RSR IMPROVED performance by 0.233 F1 points!\n",
      "  Human similarity judgments help category prediction!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 9: Comparing Models on THINGS Category Prediction\")\n",
    "print(\"=\"*70)\n",
    "print(\"Task: Predict 27 binary category labels from embeddings\")\n",
    "print(\"Method: Logistic regression with 80/20 train/test split\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def evaluate_embeddings(X, Y, C=1.0, test_size=0.2, random_state=42):\n",
    "    \"\"\"Evaluate embeddings on category prediction. Returns mean F1.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    f1_scores = []\n",
    "    for f in range(Y.shape[1]):\n",
    "        y = Y[:, f]\n",
    "        if np.all(y == y[0]):\n",
    "            continue\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        clf = LogisticRegression(C=C, max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        f1_scores.append(f1_score(y_test, clf.predict(X_test)))\n",
    "    \n",
    "    return float(np.mean(f1_scores)), float(np.std(f1_scores))\n",
    "\n",
    "# Evaluate both models\n",
    "vanilla_f1, vanilla_std = evaluate_embeddings(X_vanilla, Y)\n",
    "rsr_f1, rsr_std = evaluate_embeddings(X_rsr, Y)\n",
    "\n",
    "# Results\n",
    "print(\"=\"*70)\n",
    "print(\"RESULTS: THINGS Category Prediction (F1 Score)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  VANILLA (Wikipedia only):     F1 = {vanilla_f1:.3f} ± {vanilla_std:.3f}\")\n",
    "print(f\"  RSR (Wikipedia + Human Sim):  F1 = {rsr_f1:.3f} ± {rsr_std:.3f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "delta = rsr_f1 - vanilla_f1\n",
    "print(f\"\\n{'='*70}\")\n",
    "if delta > 0.01:\n",
    "    print(f\"✓ RSR IMPROVED performance by {delta:.3f} F1 points!\")\n",
    "    print(f\"  Human similarity judgments help category prediction!\")\n",
    "elif delta > 0:\n",
    "    print(f\"~ Slight improvement: Δ = {delta:.3f} F1\")\n",
    "else:\n",
    "    print(f\"✗ No improvement: Δ = {delta:.3f} F1\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Nearest Neighbor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NEAREST NEIGHBOR COMPARISON\n",
      "======================================================================\n",
      "\n",
      "=== 'cat' ===\n",
      "VANILLA: ['dog', 'badger', 'mouse', 'owl', 'poodle']\n",
      "RSR:     ['meerkat', 'chipmunk', 'warthog', 'pug', 'mongoose']\n",
      "\n",
      "=== 'dog' ===\n",
      "VANILLA: ['cat', 'poodle', 'pig', 'sled', 'hyena']\n",
      "RSR:     ['poodle', 'meerkat', 'pug', 'alpaca', 'mongoose']\n",
      "\n",
      "=== 'car' ===\n",
      "VANILLA: ['truck', 'limousine', 'motorcycle', 'minivan', 'engine']\n",
      "RSR:     ['minivan', 'jeep', 'limousine', 'sidecar', 'hearse']\n",
      "\n",
      "=== 'hammer' ===\n",
      "VANILLA: ['nail', 'scarecrow', 'goblet', 'anvil', 'stirrup']\n",
      "RSR:     ['pliers', 'chisel', 'screwdriver', 'sledgehammer', 'crowbar']\n",
      "\n",
      "=== 'apple' ===\n",
      "VANILLA: ['blackberry', 'rhubarb', 'lemon', 'laptop', 'juice']\n",
      "RSR:     ['blackberry', 'mango', 'cantaloupe', 'mulberry', 'guacamole']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return float(np.dot(a, b) / (norm(a) * norm(b) + 1e-8))\n",
    "\n",
    "def nearest_neighbors(word, embeddings_dict, k=5):\n",
    "    if word not in embeddings_dict:\n",
    "        return []\n",
    "    vec = embeddings_dict[word]\n",
    "    sims = [(w, cosine_sim(vec, v)) for w, v in embeddings_dict.items() if w != word]\n",
    "    return sorted(sims, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "# Create word -> embedding dicts\n",
    "vanilla_dict = {w: X_vanilla[i] for i, w in enumerate(valid_concepts)}\n",
    "rsr_dict = {w: X_rsr[i] for i, w in enumerate(valid_concepts)}\n",
    "\n",
    "# Compare nearest neighbors\n",
    "test_words = [\"cat\", \"dog\", \"car\", \"hammer\", \"apple\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEAREST NEIGHBOR COMPARISON\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for word in test_words:\n",
    "    if word not in vanilla_dict:\n",
    "        continue\n",
    "    print(f\"=== '{word}' ===\")\n",
    "    print(\"VANILLA:\", [w for w, _ in nearest_neighbors(word, vanilla_dict, 5)])\n",
    "    print(\"RSR:    \", [w for w, _ in nearest_neighbors(word, rsr_dict, 5)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Models saved to results/\n"
     ]
    }
   ],
   "source": [
    "# Save both models for later use\n",
    "import os\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': vanilla_model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'word2idx': word2idx,\n",
    "    'idx2word': idx2word,\n",
    "}, \"results/vanilla_word2vec.pt\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': rsr_model.state_dict(),\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'word2idx': word2idx,\n",
    "    'idx2word': idx2word,\n",
    "}, \"results/rsr_word2vec.pt\")\n",
    "\n",
    "print(\"✓ Models saved to results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
